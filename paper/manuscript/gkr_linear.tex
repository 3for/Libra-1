%!TEX root = fastZKP.tex
\section{GKR Protocol with Linear Prover Time}
\label{sec::gkrlin}

In this section, we present our improvements on the GKR protocol~\cite{GKR} to make the prover run in linear time for arbitrary layered circuits. We start with presenting a new linear time algorithm for the prover on certain type of sumcheck protocols, and then show how to apply it to build a linear time GRK prover.

\subsection{Linear Time Sumcheck}

Let us consider the sumcheck problem on a particular class of polynomials with specific properties. The sumcheck problem is defined as computing:
\begin{equation}\label{eq:linearsc}
f_0(g) = \sum\limits_{x,y\in\binary^\ell}f_1(g,x,y)f_2(x)f_3(y)\, ,
\end{equation}
for a random point $g\in\mathbb{F}^\ell$, where $f_0,f_2,f_3: \mathbb{F}^\ell\rightarrow\mathbb{F}$ are multilinear polynomials and $f_0(x), f_2(x)$ and $f_3(x)$ can be computed in constant time for all $x\in\binary^\ell$. $f_1:\mathbb{F}^{3\ell}\rightarrow\mathbb{F}$ is the multilinear extension of a sparse array with $O(2^\ell)$ (out of $2^{3\ell}$ possible) nonzero elements. 
It is not hard to see that the sumcheck polynomials in GRK given by Equation~\ref{eq:GKR} and~\ref{eq:randomGKR} have the similar structure.

Before presenting our new linear time algorithm for the prover on~\ref{eq:linearsc}, we first describe a building block, namely an efficient algorithm on a simpler sumcheck problem. In~\cite{t13}, Justin Thaler proposed a dynamic programming algorithm with linear prover time for the sumcheck protocol on $$\sum\limits_{x\in\binary^\ell}f(x)\, ,$$ where $f$ is a multilinear polynomial. In particular, as described in Section~\ref{subsec::sumcheck}, in the $i$-th round ($i\le \ell$), $\P$ sends $\V$ a univariate polynomial of $x_i$: $$\sum\limits_{b_{i+1}, \ldots,b_{\ell, }\in\binary}f(r_1,\ldots, r_{i-1}, x_{i}, b_{i+1},\ldots, b_{\ell})\, ,$$ where $r_1, \ldots, r_{i-1}$ are random values chosen by $\V$ in previous rounds. The degree of the univariate polynomial is 1 as $f$ is multilinear, so it suffices to send 2 evaluations of the polynomial to $\V$ at points $t = 0,1$. To compute the evaluations, the idea is that in the $i$-th round, $\P$ stores an array of values $f(r_1,\ldots, r_{i-1}, b_{i}, b_{i+1},\ldots, b_{\ell})$ for all $b_i,\ldots,b_\ell\in\binary$. The size of this array is $2^{\ell-i+1}$. With this array, $f(r_1,\ldots, r_{i-1}, t, b_{i+1},\ldots, b_{\ell})$ can be computed in constant time (see step~\ref{alg::dynamic::compute} of the Algorithm~\ref{alg::dynamic}). Therefore, prover's message $\sum\limits_{b_{i+1}, \ldots,b_{\ell, }\in\binary}f(r_1,\ldots, r_{i-1}, t, b_{i+1},\ldots, b_{\ell})$ for $t=0,1$ can be computed in time $O(2^{\ell-i+1})$ by summing up all the values in the previous step. In addition, the array that will be used in the $(i+1)$-th round can be computed in time $O(2^{\ell-i+1})$ from the array in the $i$-th round (step~\ref{alg::dynamic::update}).  In this way, the total complexity of generating all the messages in the sumcheck protocol is $O(2^{\ell})+ O(2^{\ell-1}) + O(2^{\ell-2}) + \ldots = O(2^\ell)$. The full protocol is given in Algorithm~\ref{alg::dynamic}. 



\begin{figure}[ht!]
	\begin{algorithm}[H]
		\caption{sumcheck on $\sum_{x\in\binary^\ell}f(x)$}\label{alg::dynamic}
		\begin{algorithmic}[1]
			\Procedure{{\sf Init}}{$f(x)$}
			\For{$b\in\binary^{\ell}$}
			\State $\textbf{A}[b] = f(b)$ \Comment{$b$ represents both a number and its binary representation.}
			\EndFor
			\EndProcedure
			\Procedure{\sf Update}{$\textbf{A}, r$} \Comment{This is an interactive protocol with the verifier.}
			\For{$i = 1, \ldots, \ell$} 
				\For{$b\in\binary^{\ell-i}$}
					\For{$t\in\{0,1\}$} 
					\State\label{alg::dynamic::compute} Compute $f(r_1,\ldots, r_{i-1}, t, b) = \textbf{A}[b]\cdot(1-t)+\textbf{A}[b+2^{\ell-i}]\cdot t$
					\EndFor
					
					\State\label{alg::dynamic::update} $\textbf{A}[b]=\textbf{A}[b]\cdot(1-r_i)+\textbf{A}[b+2^{s_{i+1}-j}]\cdot r_i$
				\EndFor
				\For{$t\in\{0,1\}$} 
					\State\label{alg::dynamic::sum} Compute $\sum_{b\in\binary^{\ell-i}}f(r_1,\ldots, r_{i-1}, t, b)$ and send to $\V$.
				\EndFor
			\EndFor
			\EndProcedure
		\end{algorithmic}
	\end{algorithm}
\end{figure}

Unfortunately, this algorithm does not work efficiently for the sumcheck on Equation~\ref{eq:linearsc}. This is because $f_1$ has $2^{2\ell}$ variables to sum on and naively applying Algorithm~\ref{alg::dynamic} would incur quadratic prover time $O(2^{2\ell}) = O(L^2)$, where $L = 2^\ell$. Alternatively, as $f_1$ is sparse, instead of storing $f_1(x,y)$ for all $x,y\in\binary^\ell$ in $\mathsf{Init}$, $\P$ can store only the $O(2^\ell)$ nonzero values. This is exactly the approach used in many prior work~\cite{CMT,vram,....}. However, with this approach, as $f_1$ is sparse, the number of nonzero values is not always reduced to half after every update in step~\ref{alg::dynamic::update}. Therefore, the overall complexity becomes $O(\ell 2^\ell) = L\log L$.

%We start with the sumcheck protocol to reduce a claim on layer $i$ to two claims on layer $i+1$, as defined in Definition~\ref{def::multilinear}. As shown in~\cite{CMT}, in the sumcheck protocol, the parts corresponding to $\tV_{i+1}(u)$ (and $\tV_{i+1}(v)$) can be computed in linear time by the prover using a dynamic programming technique. In particular, as introduced in Section~\ref{subsec::sumcheck}, in the $j$-th round of the sumcheck protocol, in order to compute the univariate polynomial to be sent to the verifier, the prover needs to compute $\tV_{i+1}(r_1, \ldots, r_{j-1}, t, u_{j+1}, \ldots, u_l)$ $\forall (u_{j+1},\ldots,u_l)\in\binary^{l-j}$ and $t = 0,1,2$ (as the degree of the univariate polynomial is 2 in the sumcheck of GKR, it suffices to send its evaluations on 3 points). To do this efficiently, the prover initializes an array $\textbf{V}$ of size $2^{s_{i+1}}$ storing all evaluations of $\tV_{i+1}$ on the boolean hypercube (i.e., $\tV_{i+1}(b) = V_{i+1}(b)$, $\forall b\in\{0,1\}^{s_{i+1}}$). Starting from the first round, the prover can compute each term defined above in constant time using $\textbf{V}$ (step~\ref{alg::dynamic::compute} of the Algorithm~\ref{alg::dynamic}). The array is then updated to half of the size based on the random number chosen by the verifier in this round, as in step~\ref{alg::dynamic::update}. In this way, the total complexity is $O(2^{s_{i+1}})+ O(2^{s_{i+1}-1}) + O(2^{s_{i+1}-2}) + \ldots = O(2^{s_{i+1}})$. The full protocol is given in Algorithm~\ref{alg::dynamic}. 
%
%Note that each term $v_{j,b}$ computed in step~\ref{alg::dynamic::compute} is going to be multiplied with other parts such as $\tilde{add}_{i+1}$ and $\tilde{mult}_{i+1}$ to generate the message. Unfortunately, they cannot be computed in linear time using this technique, as the size of their boolean hypercube is $2^{2s_{i+1}}$, and naively applying the same technique would incur quadratic prover time $O(2^{2s_{i+1}}) = O(S_{i+1}^2)$. This is the main reason why piror work~\cite{CMT,...} take a different approach, resulting in $O(S_{i+1}\log S_{i+1})$ prover time.

In this paper, we propose a new algorithm to reduce the prover time of the sumcheck on Equation~\ref{eq:linearsc} to linear. Our protocol divides the sumcheck into two phases: the first $\ell$ rounds bounding the variables of $x$ to a random point $u$, and the last $\ell$ rounds bounding the variables of $y$ to a random point $v$.

\begin{figure}[b!]
	\begin{algorithm}[H]
		\caption{Phase 1 in sumcheck}\label{alg::phase1}
		\begin{algorithmic}[1]
			\Procedure{{\sf Precompute}}{$g$}
			\State Set $\textbf{G}[0] = 1$
			\For{$i=0,\ldots,\ell-1$}
			\For{$b\in\binary^i$}
			\State $\textbf{G}[b,0] = \textbf{G}[b]\cdot(1-g_{i+1})$
			\State $\textbf{G}[b,1] = \textbf{G}[b]\cdot g_{i+1}$
			\EndFor
			\EndFor
			\EndProcedure
			\Procedure{{\sf Init\_PhaseOne}}{$\textbf{G}, f_3$}
			\State Initialize $\textbf{H}[b] = 0$ for $b\in\binary^\ell$
			\For{Every nonzero element in the array that defines $f_1$}
			\State Parse the index of the element as $b_1,b_2,b_3\in\binary^\ell$
			\State\label{alg::phase1::init} $\textbf{H}[b_2] = \textbf{H}[b_2]+ \textbf{G}[b_1]\cdot f_3(b_3)$
			\EndFor
			\EndProcedure
			\Procedure{{\sf Prove\_PhaseOne}}{$\textbf{H}, f_2$}
			\State $\textbf{A}_2\leftarrow\mathsf{Init}(f_2)$
			\State Run $\mathsf{Update}(\textbf{H},u)$ and $\mathsf{Update}(\textbf{A}_2,u)$ simultaneously. At step~\ref{alg::dynamic::sum}, compute $\sum_{b\in\binary^{\ell-i}}h_g(u_1,\ldots, u_{i-1}, t, b)\cdot f_2(u_1,\ldots, u_{i-1}, t, b)$ for $t\in\{0,1,2\}$ and send to the verifier.
			\EndProcedure
		\end{algorithmic}
	\end{algorithm}
\end{figure}



\paragraph{Phase one.} 
During the first $\ell$ rounds, as $y$ does not change (always being summed on the boolean hypercube), we can write Equation~\ref{eq:linearsc} as 
\[
f_0(g) = \sum_{x\in\binary^\ell} h_g(x)f_2(x),
\]
where $h_g(x) = \sum_{y\in\binary^\ell}f_1(g,x,y)f_3(y)$. Note here that both $h_g(x)$ and $f_2(x)$ contain only $\ell$ variables. We can use algorithm $\mathsf{Update}$ in Algorithm~\ref{alg::dynamic} on both to compute the messages in this phase in linear time. However, $\mathsf{Update}$ requires an array initialized with $h_g(b)$ for all $b\in\binary^\ell$. Here we utilize the sparsity of $f_1$ to develop an efficient algorithm for the initialization.

The way to do so is as following: instead of iterating through all possible $g,x,y$s, we only go through the nonzero elements that defines $f_1$. We first compute an array \textbf{G} where $\textbf{G}[b] = \prod_{i=1}^\ell ((1-g_i)(1-b_i)+g_ib_i)$ for $b\in\binary^\ell$. This can be computed in $O(2^\ell)$ as shown in Algorithm~\ref{alg::phase1}. Then for each nonzero element in the array of $f_1$, let its index be $(b_1,b_2,b_3) \in\binary^{3\ell}$, add $\textbf{G}[b_1]\cdot f_3(b_3)$ to $\textbf{H}[b_2]$. One can see that by doing so, $\textbf{H}[b] = h_g(b)$ $\forall b\in\binary^\ell$. After initializing $\textbf{H}$, we can use the dynamic programming in Algorithm~\ref{alg::dynamic} to generate the messages and update both $h_g(x)$ and $f_2(x)$. In this way, the prover runs in $O(2^\ell)$ in phase one. The full protocol is presented in Algorithm~\ref{alg::phase1}.


\paragraph{Phase two.} At this point, all variables in $x$ have been bounded to random numbers $u$. In the second phase, the equation to sum on becomes 
\[
\sum_{y\in\{0,1\}^\ell}f_1(g,u,y)f_2(u)f_3(y)
\]
Note here that $f_2(u)$ is merely a single value which we already computed in phase one at the end of the dynamic programming for $f_2(x)$. Both $f_1(g,u,y)$ and $f_3(y)$ are polynomials on $y$ with $\ell$ variables. Similar to phase one, it remains to initialize an array for $f_1(g,u,b)$ for $b\in\{0,1\}^\ell$, and we can then use Algorithm~\ref{alg::dynamic} on both of them.

The way is to compute an array \textbf{U} where $\textbf{U}[b] = \prod_{i=0}^\ell ((1-u_i)(1-b_i)+u_ib_i)$ using procedure $\mathsf{Precompute}(u)$ in Algorithm~\ref{alg::phase1}. Then for each nonzero element with index $b_1,b_2,b_3$ that defines $f_1$, add $\textbf{G}[b_1]\cdot\textbf{U}[b_2]$ to $\textbf{A}_1[b_3]$. In this way, $\textbf{A}_1[b_3]=f_1(g,u,b_3)$ $\forall b_3\in\binary^\ell$. Then we use Algorithm~\ref{alg::dynamic} on both $\textbf{A}_1$ and $f_3(y)$ to run the sumcheck in this phase in linear time. The protocol is presented in Algorithm~\ref{alg::phase2}.


\begin{figure}[b!]
	\begin{algorithm}[H]
		\caption{Phase 2 in sumcheck}\label{alg::phase2}
		\begin{algorithmic}[1]
			\Procedure{{\sf Init\_PhaseTwo}}{$u$}
			\State Set $\textbf{U} = \mathsf{Precompute}(u)$
			\State Initialize $\textbf{A}_1[b] = 0$ for $b\in\binary^\ell$
			\For{Every nonzero element in the array that defines $f_1$}
			\State Parse the index of the element as $b_1,b_2,b_3\in\binary^\ell$
			\State\label{alg::phase2::init} $\textbf{A}_1[b_3] = \textbf{A}_1[b_3]+ \textbf{G}[b_1]\cdot\textbf{U}[b_2]$
			\EndFor
			\EndProcedure
			\Procedure{{\sf Prove\_PhaseTwo}}{$\textbf{A}_1, f_3$}
			\State $\textbf{A}_3\leftarrow\mathsf{Init}(f_3)$
			\State Run $\mathsf{Update}(\textbf{A}_1, v)$ and $\mathsf{Update}(\textbf{A}_3,v)$ simultaneously. At step~\ref{alg::dynamic::sum}, compute $\sum_{b\in\binary^{\ell-i}}f_1(g,u, v_1, \ldots,v_{i-1}, t, b)\cdot f_2(u)\cdot f_3(v_1, \ldots,v_{i-1}, t, b)$ for $t\in\{0,1,2\}$ and send to the verifier.
			\EndProcedure
		\end{algorithmic}
	\end{algorithm}
\end{figure}


\paragraph{Generalizations.}
\yupeng{Give a general form of sumcheck equations that can be computed in linear time. No need to show algorithms.}

\subsection{Linear Time GKR}

The sumcheck protocol in GKR given by Equation~\ref{eq:GKR} can be decomposed into several instances that has the form of Equation~\ref{eq:linearsc} presented in the previous section. The term $\sum_{x,y\in\binary^{s_{i+1}}}\tmult_{i+1}(g,x,y)(\tV_{i+1}(x)\tV_{i+1}(y))$ is exactly the same as Equation~\ref{eq:linearsc}.  The term $\sum_{x,y\in\binary^{s_{i+1}}}\tadd_{i+1}(g,x,y)(\tV_{i+1}(x)+\tV_{i+1}(y))$ can be viewed as: 
\[
\sum_{x,y\in\binary^{s_{i+1}}}\tadd_{i+1}(g,x,y)\tV_{i+1}(x)+\sum_{x,y\in\binary^{s_{i+1}}}\tadd_{i+1}(g,x,y)\tV_{i+1}(y)
\]
The first sum can be computed using the same protocol in Algorithms~\ref{alg::phase1} and~\ref{alg::phase2} without $f_3(y)$, and the second sum can be computed without $f_2(x)$. The complexity for both cases remains linear. Due to linearity of the sumcheck protocol, the prover can execute these 3 instances simultaneously in every round, and sum up the values computed in step~\ref{alg::dynamic::sum} of Algorithm~\ref{alg::dynamic} as the message to send to the verifier.



\paragraph{Combining two claims.} After the sumcheck in the GKR protocol, as described in Section~\ref{subsec::GKR}, the prover and the verifier need to combine the two claims about $\tV_{i+1}$ received at the end of the sumcheck protocol to one to avoid the exponential blow-up. There are two ways to combine the two claims and we show how to do each of them in linear time. 

The second approach using random linear combinations is rather straight forward. After the output layers, $\P$ and $\V$ execute sumcheck protocol on Equation~\ref{eq:randomGKR} instead of Equations~\ref{eq:GKR}, which still satisfies the properties of Equation~\ref{eq:linearsc}. One could view it as 6 instances of Equation~\ref{eq:linearsc} and the prover time is still linear. Moreover, there is a better way to further improve the efficiency. Taking $\sum_{x, y \in\binary^{s_{i+1}}}(\alpha_i\tmult_{i+1}(u,x,y)+\beta_i\tmult_{i+1}(v,x,y))\tV_{i+1}(x)\tV_{i+1}(y)$ as an example, in Algorithm~\ref{alg::phase1}, the prover runs $\mathsf{Precompute}$ twice on $u$ and $v$ to generate two arrays ($\textbf{G}_1$ and $\textbf{G}_2$), and sets $\textbf{G}[b]=\alpha_i \textbf{G}_1[b] + \beta_i\textbf{G}_2[b]$ for all $b$. The rest of the algorithms remains the same. This modified algorithm incurs a small overhead in practice in our implementation, compared to the original algorithm on Equation~\ref{eq:linearsc}.

Though with the approach above we already have a linear prover GKR protocol, the technique to condense two points to one proposed in the original GKR protocol~\cite{GKR} may still be interesting in some scenarios (e.g., in our implementation, we use this approach in the last layer and only make one query to the multi-linear extension of the input, which is more efficient practice). We present an algorithm for this approach that reduces the prover time to linear in Appendix~\ref{app:onepoint}.





\ignore{
	\subsubsection{Linear Prover Time Sumcheck}
	We will follow the CMT protocol, and improve the performance of sumcheck and the performance of combining two points. We will break the protocol into two parts, the first part deal with queries about $u$, and the second part will deal with queries about $v$.
	\subsubsection{Part One} In this part, we will deal with queries in first $s_{i+1}$ rounds.
	\paragraph{Review the sumcheck}
	In this subsection, we focus on answering the sumcheck queries. In the first round, the verifier asks the prover to give a univariate function: 
	
	$$f_{i, 1}(x_1)=\sum_{u_{k} \in \{0, 1\}, v \in \{0, 1\}^{s_{i+1}}}\tilde{mult}_{i}(g, \{x_1, u_{2},..., u_{s_{i+1}}\}, v)(\tV_{i+1}(x_1, u_{2},..., u_{|u|})\tV_{i+1}(v)),$$
	where $v$ is a binary vector in $\{0, 1\}^{s_{i+1}}$, $\{x_1, u_{2},..., u_{s_{i+1}}\}$ is the representation of $u$.
	
	In the $k$-th round where $2\le k\le s_{i+1}$, the verifier asks the prover to give a univariate function:
	\begin{align*}
	f_{i,k}(x_k)=\sum_{u_k \in \{0, 1\}, v \in \{0, 1\}^{s_{i+1}}}\tilde{mult}_{i}(g, \{r_1,r_2,...,r_{k-1},x_k, u_{k+1},..., u_{s_{i+1}}\}, v)\times\\
	(\tV_{i+1}(r_1,r_2,...,r_{k-1},x_k, u_{k+1},..., u_{s_{i+1}})\tV_{i+1}(v))
	\end{align*}
	where $v$ is a binary vector in $\{0, 1\}^{s_{i+1}}$, $\{r_1,r_2,...,r_{k-1},x_k, u_{k+1},..., u_{s_{i+1}}\}$ is the representation of $u$.
	
	\paragraph{The Definition of Building Block}
	In the first round, we calculate two arraies to help speed up calculation, where each array element is a pair $(a, b)$ representing a linear function $ax+b$.
	
	The first array is $mult_1^1$, where $mult_1^1[p]$ is a pair $(a, b)$ representing a linear function as follows:
	$${mult}_1^1[p]\overset{def}{=}\sum_{v\in \{0,1\}^{s_{i+1}}}\tilde{mult}_i(g, \{x_1, p\}, v)\tV_{i+1}(v),$$
	here $p$ is a $s_{i+1}-1$ bits binary number. $\{x_1, p\}$ is the representation of $u$. Similarly we define our second array ${V}_1^1[p]$ as follows:
	$$V_1^1[p]\overset{def}{=}\tV_i(\{x_1, p\})$$
	
	We will treat both arrays as a linear function or a pair of field elements interchangeably, for example ${mult}_1^1[p](x)$ means we treat it as a linear function, and ${mult}_1^1[p].a, {mult}_1^1[p].b$ means we treat it as a pair.
	
	Similarly we define arrays that used in $k$-th round as follows:
	\begin{definition}[Linear Function Array Part One]
		
		The definition for $k=1$ is the statement above, for $k\ge 2$
		\begin{enumerate}
			\item ${mult}_k^1[p]\overset{def}{=}\sum_{v\in \{0, 1\}^{s_{i+1}}}\tilde{mult}_i(g, \{r_1, ..., r_{k-1}, x_k, p\}, v)\tV_{i+1}(v)$
			\item ${V}_k^1[p]\overset{def}{=}\tV_i(\{r_1, ..., r_{k-1}, x_k, p\})$
			\item Where $p$ is a $s_{i+1}-k$ bits binary number and $\{r_1, ..., r_{k-1}, x_k, p\}$ is the representation of $u$.
		\end{enumerate}
	\end{definition}
	
	\paragraph{Initialize Arrays}
	We will try to initialize ${mult}_1^1, {V}_1^1$. And we will calculate next arrays using these arrays.
	
	For ${V}_1^1$, we can scan through the circuit and get all values of $\tV_{i+1}(u)$ when $u \in \{0, 1\}^{s_{i+1}}$, and we have the following equations:
	\begin{align*}
	{V}_1^1[p](0)=\tV_{i+1}(0||p)\\
	{V}_1^1[p](1)=\tV_{i+1}(1||p)
	\end{align*}
	We can solve for ${V}_1^1[p]$ easily.
	
	For ${mult}_1^1$, the idea is the same as ${V}_1^1$, but it's non-trivil to calculate $\sum_{v\in \{0,1\}^{s_{i+1}}}\tilde{mult}_{i+1}(g, u, v)\tV_{i+1}(v)$ for every binary $u$ in linear time, since we need to calculate $\tilde{\beta}_{s_{i}}(g, g')$ part in $\tilde{mult}_{i+1}(g, u, v)$. Instead enumerate every binary $u$ to initialize the array, we can enumberate $g'$ instead. And accumulate the contribution of $(g', u', v')$ to $\sum_{v\in \{0,1\}^{s_{i+1}}}\tilde{mult}_{i+1}(g, u', v)\tV_{i+1}(v)$. We will use a depth first search to enumerate every $g'$ bit by bit. The detailed algorithm is shown in Algorithm \ref{alg::premult}.
	\begin{figure}[p]
		\begin{algorithm}[H]
			\label{alg::premult}
			\caption{Preprocess ${mult}_1^1, {V}_1^1$}
			\begin{algorithmic}[1]
				\parState{Assuming we have global access to $g$, $s_i$, $s_{i+1}$, which is resonable since prover knows these values, and $g[k]$ means the $k$-th field element of $g$, starting from $0$ since we are writing pseudo-code}
				\Procedure{{\sf DFS}}{$A$, $g'$, $depth$, $Value$}
				\parState{Note $A$, $g'$ is the pointer to the array, any change to $A$ or $g'$ will change it globally.}
				\parState{In this function, we will recurse on the bits of $g$}
				\If {$depth=s_{i}$} \Comment{We have enumerate enough bits}
				\State Let $u', v'$ is input gates to $g'$
				\State Find $\tV_{i+1}(v')$ in circuit.
				\State $A[u'] = A[u'] + \tV_{i+1}(v')\times Value$
				\Else
				\State set $g'[depth]=0$
				\State Call {\sf DFS}($A$, $g'$, $depth+1$, $Value\times(1-g[depth])$)
				\State set $g'[depth]=1$
				\State Call {\sf DFS}($A$, $g'$, $depth+1$, $Value\times g[depth]$)
				\EndIf
				\EndProcedure
				\Procedure{{\sf InitializeMult}}{}
				\State Let array ${mult}_1^1$ be filled with zeros.
				\parState{Since calculate $\sum_{v\in \{0,1\}^{s_{i+1}}}\tilde{mult}_{i+1}(g, u, v)\tV_{i+1}(v)$ for every binary $u$ is enough to initialize array ${mult}_1^1$, we will call a subroutine to initialize every binary $u$, and store the result into array $A$.}
				\State Initialize array $A$ with zeros.
				\State let $g'$ be a vector of $s_{i+1}$ bits.
				\State Call {\sf DFS}($A$, $g'$, $0$, $1$)
				\For{each $p \in \{0, 1\}^{s_{i+1}-1}$}
				\parState{By solving the linear equations, we can get the following statements}
				\State ${mult}_1^1[p].b=A[0||p]$
				\State ${mult}_1^1[p].a=A[1||p]-A[0||p]$
				\EndFor
				\EndProcedure
			\end{algorithmic}
		\end{algorithm}
	\end{figure}
	
	\paragraph{Answer Queries}
	The answer to the first query is the following univariate function:
	
	$$\sum_{p}{mult}_1^1[p](x)\times{V}_1^1[p](x),$$
	
	It's easy to get this result by doing some transformation on the original equation.
	
	We reduce these arraies to the second round using the following way
	
	\begin{enumerate}
		\item By definition, ${mult}_2^1[p'](0)={mult}_1^1[0||p'](r_1)$ and ${mult}_2^1[p'](1)={mult}_1^1[1||p'](r_1)$
		\item By definition, ${V}_2^1[p'](0)={V}_1^1[0||p'](r_1)$ and ${V}_2^1[p'](1)={V}_1^1[1||p'](r_1)$
		
		\item Since both ${mult}_2^1, {V}_2^1$ are linear equations, we can solve the ${mult}_2^1, {V}_2^1$ by solving linear equations.
		\item By solving linear equations we found that ${mult}_2^1[p'].b={mult}_1^1[0||p'](r_1)$ and ${mult}_2^1[p'].a={mult}_1^1[1||p'](r_1)-{mult}_1^1[0||p'](r_1)$
	\end{enumerate}
	
	The answer to the second round is 
	
	$$\sum_{p'}{mult}_2^1[p']\times{V}_2^1[p']$$
	
	We define arrays for the $k$-th round ($k\ge 2$) in the similarly using the result from $k-1$-th round, and solving the linear equation.
	
	The answer to the $k$-th round query is 
	$$\sum_{p}{mult}_k^1[p]\times{V}_k^1[p]$$
	
	\begin{theorem} For every round, the algorithm above correctly answered the query. And the running time of the algorithm runs in time $O(\max(2^{s_i}, 2^{s_{i+1}}))$.
	\end{theorem}
	
	\begin{proof}
		It's trivial to see that ${mult}_k^1, {V}_k^1$ are computed correctly. 
		
		For time complexity part, ${mult}_k^1, {V}_k^1$ are computed in linear time since Algorithm \ref{alg::premult} runs in linear time, and for $k$-th layer, the size of ${mult}_k^1$ is half size of ${mult}_{k-1}^1$, by total size of these arraies is linear to the circuit size.
		
		The answer to the verifier is correct by the definition of ${mult}_k^1, {V}_k^1$.
	\end{proof}
	
	\subsubsection{Part two}
	In this part, we will deal with next $s_{i+1}$ rounds. In these rounds, $g, u$ are fixed random vector with $s_{i}, s_{i+1}$ random field elements respectively.
	
	\paragraph*{Initialize Arrays}
	We define two arrays ${mult}_k^2, {V}_k^2$ analogue to ${mult}_k^1, {V}_k^1$.
	
	\begin{definition}[Linear Function Array Part Two]
		For $k=1$, we define 
		\begin{enumerate}
			\item ${mult}_1^2[p] = \tilde{mult}_i(g, u, \{x_1, p\})\tV_{i+1}(u)$
			\item ${V}_1^2[p] = \tV_{i+1}(\{x_1, p\})$
		\end{enumerate}
		For $k\ge 2$, we define
		\begin{enumerate}
			\item ${mult}_k^2[p]\overset{def}{=}\tilde{mult}_i(g, u, \{r_1, ..., r_{k-1}, x_k, p\})\tV_{i+1}(u)$
			\item ${V}_k^2[p]\overset{def}{=}\tV_i(\{r_1, ..., r_{k-1}, x_k, p\})$
			\item Where $p$ is a $s_{i+1}-k$ bits binary number and $\{r_1, ..., r_{k-1}, x_k, p\}$ is the representation of $v$.
		\end{enumerate}
	\end{definition}
	
	As we discussed in Part One, we only need to calculate all the values of ${mult}_k^2, {V}_k^2$. By the definition of $\tilde{mult}_i(g, u, v)\overset{def}{=}\sum_{g', u', v' \in G_{i, mult}}\tilde{\beta_{s_i}}(g, g')\tilde{\beta_{s_{i+1}}}(u, u')\tilde{\beta_{s_{i+1}}}(v, v')$. We found that $\tilde{mult}_i$ is composed by three seperate functions. Since $g, u$ are fixed random vector, we can preprocess $\tilde{\beta}_{s_i}(g, g')$ for every binary $g'$ and preprocess $\tilde{\beta}_{s_{i+1}}(u, u')$ for every binary $u'$. See the detailed algorithm in Algorithm \ref{alg::parttwo}.
	
	\begin{figure}[p]
		\begin{algorithm}[H]
			\label{alg::parttwo}
			\caption{Preprocess $mult_1^2, V_1^2$}
			\begin{algorithmic}[1]
				\parState{Array/Vector parameters are passed by pointer, any change to the array will effect the array globally}
				\Procedure{{\sf DFS}}{$A, x, randVec, depth, maxDepth, value$}
				\If{$depth=maxDepth$}
				\State $A[x]=value$
				\Else
				\State set $x[depth]=0$
				\State Call DFS($A$, $x$, $depth + 1$, $value \times (1-randVec[depth])$)
				\State set $x[depth]=1$
				\State Call DFS($A$, $x$, $depth + 1$, $value \times randVec[depth]$)
				\EndIf
				\EndProcedure
				\Procedure{{\sf PreprocessBeta}}{$BetaMult, BetaV$}
				\State let $g', u'$ be zero $s_{i}, s_{i+1}$ length vector
				\State Call {\sf DFS}($BetaMult$, $g'$, $g$, $0$, $s_{i}$, $1$)
				\State Call {\sf DFS}($BetaV$, $u'$, $u$, $0$, $s_{i + 1}$, $1$)
				\EndProcedure
				\Procedure{{\sf Preprocess}}{${Mult}_1^2, {V}_1^2$}
				\State Let $BetaMult, BetaV$ be a array with length $2^{s_{i}}, 2^{s_{i+1}}$ respectively
				\State Call {\sf PreprocessBeta}($BetaMult$, $BetaV$)
				\State Let $MultBinaryU$ be a array with $2^{s_{i+1}}$ field elements, initially set to $0$.
				\parState{The array $MultBinaryU[v'] \overset{def}{=}\tilde{mult}_i(g, u, v')\tV_{i+1}(u)$}, we will show that how to compute this array in this For loop.
				\For{Each $v' \in \{0, 1\}^{s_{i+1}}$}
				\For{Each $(g', u')$ that is connected to $v'$ in the circuit}
				\State $MultBinaryU[v'] += BetaMult[g'] \times BetaV[u'] \times \tV_{i+1}[u]$
				\parState{Since $u$ is a constant, $\tV_{i+1}[u]$ is a constant all the time as well, we can obtain the value from the result of Part One (It equals to $V_{s_{i+1}-1}^1[0](r_{s_{i+1}})$ by the definition of $V_{k}^1$).}
				\EndFor
				\EndFor
				
				\For {each $p \in \{0, 1\}^{s_{i+1}-1}$}
				\parState{By solving the linear equations , we can get the following statements}
				\State $Mult_1^2[p].b = MultBinaryU[0||p]$
				\State $Mult_1^2[p].a = MultBinaryU[1||p]-MultBinaryU[0||p]$
				\parState{$\tV_{s_{i+1}}[v']$ is the value directly from the circuit, we assume it's preprocessed into a array.}
				\State $V_1^2[p].b = \tV_{s_{i+1}}[0||p]$
				\State $V_1^2[p].a = \tV_{s_{i+1}}[1||p]-\tV_{s_{i+1}}[0||p]$
				\EndFor
				\EndProcedure
			\end{algorithmic}
		\end{algorithm}
	\end{figure}
	
	\paragraph*{Answer Queries}
	The answer to the first query is the following univariate function:
	
	$$\sum_{p}mult_{1}^2[p](x)\times V_1^2[p](x)$$
	
	It's easy to check that this summation is equals to the original sumcheck summation.
	
	To answer $k$-th query ($k\ge 2$), we suppose we have answered the $k-1$-th query and generated arrays $mult_{k-1}^2, V_{k-1}^2$, we generate $mult_{k}^2, V_{k}^2$ and answer the $k$-th query in the following way:
	
	\begin{enumerate}
		\item By definition, $\forall p \in {\{0, 1\}^{s_{i+1}-k}}$, $mult_{k}^2[p](0)=mult_{k-1}^2[0||p](r_{k-1}), mult_{k}^2[p](1)=mult_{k-1}^2[1||p](r_{k-1})$
		\item By definition, $\forall p \in {\{0, 1\}^{s_{i+1}-k}}$, $V_{k}^2[p](0)=V_{k-1}^2[0||p](r_{k-1}), V_{k}^2[p](1)=V_{k-1}^2[1||p](r_{k-1})$
		\item Since $mult_{k}^2[p], V_{k}^2[p]$ are linear function, we can solve the equations above. We have the following results.
		\item $\forall p \in {\{0, 1\}^{s_{i+1}-k}}$, $mult_{k}^2[p].b = mult_{k-1}^2[0||p](r_{k-1}), mult_{k}^2[p].a = mult_{k-1}^2[1||p](r_{k-1})-mult_{k-1}^2[0||p](r_{k-1})$
		\item $\forall p \in {\{0, 1\}^{s_{i+1}-k}}$, $V_{k}^2[p].b = V_{k-1}^2[0||p](r_{k-1}), V_{k}^2[p].a = V_{k-1}^2[1||p](r_{k-1})-V_{k-1}^2[0||p](r_{k-1})$
		\item For $k$-th round, the answer to the query is $\sum_{p} mult_{k}^2[p](x)\times V_{k}^2[p](x)$
	\end{enumerate}
	
	\begin{theorem} The algorithm above correctly answered querys of last $s_{i+1}$ rounds, and runs in time $O(\max(2^{s_{i}}, 2^{s_{i+1}}))$.
	\end{theorem}
	
	\begin{proof}
		Since we only need to scan through the circuit, the time complexity is linear for initialize $mult_{1}^2, V_1^2$. The size of $mult_{k}^2, V_k^2$ is half of $mult_{k-1}^2, V_{k-1}^2$. The total size of $mult_{k}^2, V_k^2$ is linear to the size of $mult_1^2, V_1^2$, which is the circuit size. And to answer the query, we only need to scan through these arrays. The total time complexity is linear to the circuit size.
		
		If $mult_k^2, V_k^2$ are generated correctly, the answer to the query is correct by definition.
		
		$V_1^2$ is correct since it's equal to the circuit value. $mult_1^2$ is correct if and only if $MultBinaryU$ is generated correctly. $\forall g'$, $BetaMult[g']$ is correct because we calculated it bit by bit according to definition in $DFS$ part. And so does $BetaV[u']$. By definition 
		\begin{align*}
		MultBinaryU[v']&\overset{def}{=}\tilde{mult}_{i}(g, u, v')\tV_{i+1}(u)
		\\&=\sum_{v=v', (g', u', v) \in G_{i, mult}}\tilde{\beta}_{s_{i}}(g, g')\tilde{\beta}_{s_{i+1}}(u, u')\tilde{\beta}_{s_{i+1}}(v, v')\tV_{i+1}(u)
		\\&=\sum_{v=v', (g', u', v) \in G_{i, mult}}\tilde{\beta}_{s_{i}}(g, g')\tilde{\beta}_{s_{i+1}}(u, u')\tV_{i+1}(u)
		\end{align*}
		
		Since $BetaMult[g'], BetaV[u']$ are correct, we have $MultBinaryU$ is correct. Thus $mult_1^2$ is correct.
		
		To prove $mult_k^2, V_k^2$ is correct ($k \ge 2$). We assume $mult_{k-1}^2, V_{k-1}^2$ is correct. According to the definition of $mult_k^2$, $mult_k^2[p](0)=\tilde{mult}_i(g, u, {r_1, r_2,...,r_{k-1}, 0, p})=mult_{k-1}^2[0||p](r_{k-1})$, $mult_k^2[p](1)=\tilde{mult}_i(g, u, {r_1, r_2,...,r_{k-1}, 1, p})=mult_{k-1}^2[1||p](r_{k-1})$, by solving the linear equation, we can get the right value of $mult_k^2[p]$. And we have a similar arguement of $V_k^2$.
	\end{proof}
}