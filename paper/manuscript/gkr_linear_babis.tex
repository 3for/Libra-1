%!TEX root = fastZKP.tex
\section{GKR Protocol with Linear Prover Time}
\label{sec::gkrlin}

In this section we present a new algorithm for the prover of the GKR protocol~\cite{GKR} that runs in linear time for \emph{arbitrary layered circuits}. Before that we present some necessary building blocks.
%We start with presenting a new linear time algorithm for the prover on certain type of sumcheck protocols, and then show how to apply it to build a linear time GRK prover.

\subsection{Linear-time sumcheck for a multilinear function~\cite{JT_Thesis}}
In~\cite{JT_Thesis}, Thaler proposed a linear-time algorithm for the prover of the sumcheck protocol on a multilinear function $f$ on $\ell$ variables (the algorithm runs in $O(2^\ell)$ time). We review this algorithm here. Recall that in the $i$-th round of the sumcheck protocol the prover sends the verifier the univariate polynomial on $x_i$ $$\sum_{b_{i+1}, \ldots,b_{\ell, }\in\binary}f(r_1,\ldots, r_{i-1}, x_{i}, b_{i+1},\ldots, b_{\ell})\, ,$$
where $r_1, \ldots, r_{i-1}$ are random values chosen by the verifier in previous rounds. Since $f$ is multilinear, it suffices for the prover to send two evaluations of the polynomial at points $t = 0$ and $t=1$, namely the evaluations
\begin{equation}\label{0-message}
\sum_{b_{i+1}, \ldots,b_{\ell, }\in\binary}f(r_1,\ldots, r_{i-1}, 0, b_{i+1},\ldots, b_{\ell})
\end{equation} and  
\begin{equation}\label{1-message}
\sum_{b_{i+1}, \ldots,b_{\ell, }\in\binary}f(r_1,\ldots, r_{i-1}, 1, b_{i+1},\ldots, b_{\ell})\,.
\end{equation}



To compute the above sums the prover maintains a \emph{bookkeeping table} $\textbf{A}$ for $f$. This table, at round $i$, has $2^{\ell-i+1}$ entries storing the values $$f(r_1,\ldots, r_{i-1}, b_{i}, b_{i+1},\ldots, b_{\ell})$$ for all $b_i,\ldots,b_\ell\in\binary$ and is initialized with evaluations of $f$ on the hypercube. For every entry of $\textbf{A}$, the prover subsequently computes two values $$f(r_1,\ldots, r_{i-1}, 0, b_{i+1},\ldots, b_{\ell}) 
\text{ and } f(r_1,\ldots, r_{i-1}, 1, b_{i+1},\ldots, b_{\ell})\,.$$ This is performed in constant time in Step~\ref{alg:func_eval} of Algorithm~\ref{alg:evaluate} \textsf{FunctionEvaluations}\footnote{To be compatible with other protocols later, we use three values $t=0,1,2$ in our evaluations instead of just two.}. Once these function evaluations are in place, the prover can easily sum over them and compute the required sumcheck messages as reguired by Relations~\ref{0-message} and~\ref{1-message}. This is done in Algorithm~\ref{alg:sumcheck} \textsf{SumCheck}\footnote{We note here that although these two steps  can be performed together in a single algorithm and without the need to store function evaluations, we explicitly decouple them with two different algorithms (\textsf{FunctionEvaluations} and \textsf{SumCheckMessages}) for facilitating the presentation of more advanced protocols later. }. 

\paragraph{Complexity analysis.} 
At a first glance, it seems that both Algorithms~\ref{alg:evaluate} and~\ref{alg:sumcheck} run in $O(2^\ell)$ time: The first iteration takes $O(2^\ell)$, the second $O(2^{\ell-1})$ and so on, and therefore the bound holds. However, this analysis is correct provided the bookkeeping table $\textbf{A}$ for $f$ can be initialized in $O(2^\ell)$ time in Step~\ref{bookkeeping_step} of Algorithm~\ref{alg:evaluate}. As we will see in Section~\ref{particular} this is not always trivial to achieve. However, in case $f$ is provided as an array of evaluations on the hypercube, both Algorithms~\ref{alg:evaluate} and~\ref{alg:sumcheck} run in $O(2^\ell)$ time. 







\begin{figure}
\begin{algorithm}[H]
		\caption{$\mathcal{F}\leftarrow \textsf{FunctionsEvaluations}(f,r_1,\ldots,r_\ell)$}\label{alg:evaluate}
		 \textbf{Input:} Multilinear function $f$ on $\ell$ variables and randomness $r_1,\ldots,r_\ell$;  \\
    \textbf{Output:} All function evaluations $f(r_1,\ldots, r_{i-1}, t, b_{i+1},\ldots, b_{\ell})$; 
   
		\begin{algorithmic}[1]
		 
\State \label{bookkeeping_step}Let $\textbf{A}$ be the bookeeping table storing the evaluations of $f$ on the hypecube
					\For{$i = 1, \ldots, \ell$} 
				\For{$b\in\binary^{\ell-i}$} \Comment{$b$ is both a number and its binary representation.} \label{step:consider_b}
	\For{$t= 0,1,2$} 				
					 \State \label{alg:func_eval} Let $f(r_1,\ldots, r_{i-1}, t, b) = \textbf{A}[b]\cdot (1-t)+\textbf{A}[b+2^{\ell-i}]\cdot t$
					\EndFor
					
					
					
					\State\label{alg::dynamic::update} $\textbf{A}[b]=\textbf{A}[b]\cdot(1-r_i)+\textbf{A}[b+2^{\ell-i}]\cdot r_i$
				\EndFor
%					\EndFor
%\For{$i = 1, \ldots, \ell$} 
								
		
		\EndFor	
		\State Let $\mathcal{F}$ contain all function evaluations $f(.)$ computed at Step~\ref{alg:func_eval}
		\State \textbf{return} $\mathcal{F}$
		\end{algorithmic}
	\end{algorithm}
	
\end{figure}

\begin{figure}[t!]
    
	\begin{algorithm}[H]
		\caption{$\{a_1,\ldots,a_\ell \}\leftarrow \textsf{SumCheck}(f,r_1,\ldots,r_\ell)$}\label{alg:sumcheck}
		 \textbf{Input:} Multilinear function $f$ on $\ell$ variables and randomness $r_1,\ldots,r_\ell$;  \\
    \textbf{Output:} 
    $\ell$ sumcheck messages for $\sum_{x\in\binary^\ell}f(x)$. Each message $a_i$ consists of 3 elements $(a_{i0},a_{i1},a_{i2})$; 
   
		\begin{algorithmic}[1]
		 
\State $\mathcal{F}\leftarrow \textsf{FunctionEvaluations}(f,r_1,\ldots,r_\ell)$
					\For{$i = 1, \ldots, \ell$} 
								\For{$t\in\{0,1,2\}$}
					\label{alg::dynamic::sum0} \State $a_{it}=\sum_{b\in\binary^{\ell-i}}f(r_1,\ldots, r_{i-1}, t, b)$ \Comment{All evaluations needed are in $\mathcal{F}$.}

					
	\EndFor
				
		
		\EndFor	
		\State \textbf{return} $\{a_1,\ldots,a_\ell \}$;
		\end{algorithmic}
	\end{algorithm}
	
\end{figure}
\begin{figure}
\begin{algorithm}[H]
		\caption{$\{a_1,\ldots,a_\ell \}\leftarrow \textsf{SumCheckProduct}(f,g,r_1,\ldots,r_\ell)$}\label{alg:sumcheckproduct}
		 \textbf{Input:} Multilinear functions $f$ and $g$ on $\ell$ variables and randomness $r_1,\ldots,r_\ell$;  \\
    \textbf{Output:} 
    $\ell$ sumcheck messages for $\sum_{x\in\binary^\ell}f(x)g(x)$. Each message $a_i$ consists of 3 elements $(a_{i0},a_{i1},a_{i2})$; 
   
		\begin{algorithmic}[1]
		 
\State $\mathcal{F}\leftarrow \textsf{FunctionEvaluations}(f,r_1,\ldots,r_\ell)$
\State $\mathcal{G}\leftarrow \textsf{FunctionEvaluations}(g,r_1,\ldots,r_\ell)$

					\For{$i = 1, \ldots, \ell$} 
								\For{$t\in\{0,1,2\}$}
					\label{alg::dynamic::sum0} \State $a_{it}=\sum_{b\in\binary^{\ell-i}}f(r_1,\ldots, r_{i-1}, t, b)\cdot g(r_1,\ldots, r_{i-1}, t, b)$ \Comment{All evaluations needed are in $\mathcal{F}$ and $\mathcal{G}$.}

					
	\EndFor
				
		
		\EndFor	
		\State \textbf{return} $\{a_1,\ldots,a_\ell \}$;
		\end{algorithmic}
	\end{algorithm}
	
\end{figure}
\subsection{Linear-time sumcheck for a product of two multilinear functions\label{particular}}
Let now $f$ and $g$ be two multilinear functions on $\ell$ variables each. In this section we present a linear-time algorithm to compute the messages of the prover for the sumcheck on the product $f\cdot g$. Note that we cannot use Algorithm~\ref{alg:sumcheck} here since $f\cdot g$ is not multilinear. However, similarly with the single-function case, the prover must now send, at round $i$, the following evaluations at points $t = 0$, $t=1$ and $t=2$

$$\sum_{b_{i+1}, \ldots,b_{\ell, }\in\binary}f(r_1,\ldots, r_{i-1}, t, b_{i+1},\ldots, b_{\ell})\cdot g(r_1,\ldots, r_{i-1}, t, b_{i+1},\ldots, b_{\ell}) $$
The above can be easily computed by computing evaluations for functions $f$ and $g$ \emph{separately} using Algorithm~\ref{alg:evaluate} and the combining the results using our new Algorithm~\ref{alg:sumcheckproduct} $\textsf{SumCheckProduct}$. We now have the following lemma:
\begin{lemma}\label{main_lemma_complexity}
Algorithm $\textsf{\emph{SumCheckProduct}}(f,g,r_1,\ldots,r_\ell)$ runs in time $O(2^\ell + T)$, where $T$ is the time for initializing the bookkeeping tables of $f$ and $g$.
\end{lemma}
\begin{proof}
All loops in \textsf{SumCheckProduct} require time $2^\ell+2^{\ell-1}+\ldots=O(2^\ell)$. Also $\textsf{SumCheckProduct}$ calls $\textsf{FunctionEvaluations}$ twice (one for $f$ and one for $g$) and each such call must initialize the respective bookkeeping table. Therefore the bound holds.
\end{proof}



\subsection{Linear-time sumcheck for GKR functions}
Let us now consider the sumcheck problem on a particular class of functions that are relevant for the GKR protocol (that is why we call them GKR functions). In particular we want to compute the sumcheck 
\begin{equation}\label{eq:linearsc}
\sum\nolimits_{x,y\in\binary^\ell}f_1(g,x,y)f_2(x)f_3(y)\, ,
\end{equation}
for a fixed point $g\in\mathbb{F}^\ell$, where $f_2(x),f_3(x): \F^\ell\rightarrow \F$ are multilinear extensions of arrays of size $2^\ell$ and function $f_1:\mathbb{F}^{3\ell}\rightarrow\mathbb{F}$ is the multilinear extension of a sparse array with $O(2^\ell)$ (out of $2^{3\ell}$ possible) nonzero elements. 
It is not hard to see that the sumcheck polynomials in GKR given by Equation~\ref{eq:GKR} and~\ref{eq:randomGKR} satisfy these properties.


% \begin{figure}[b!]
%     \vspace{-.5in}
% 	\begin{algorithm}[H]
% 		\caption{sumcheck on $\sum_{x\in\binary^\ell}f(x)$}\label{alg::dynamic}
% 		\begin{algorithmic}[1]
% 			\Procedure{{\sf Init}}{$f(x)$}
% 			\For{$b\in\binary^{\ell}$}
% 			\State $\textbf{A}[b] = f(b)$ \Comment{$b$ represents both a number and its binary representation.}
% 			\EndFor
% 			\EndProcedure
% 			\Procedure{\sf Update}{$\textbf{A}, r$} \Comment{This is an interactive protocol with the verifier.}
% 			\For{$i = 1, \ldots, \ell$} 
% 				\For{$b\in\binary^{\ell-i}$}
% 					\For{$t\in\{0,1\}$} 
% 					\State\label{alg::dynamic::compute} Compute $f(r_1,\ldots, r_{i-1}, t, b) = \textbf{A}[b]\cdot(1-t)+\textbf{A}[b+2^{\ell-i}]\cdot t$
% 					\EndFor
					
% 					\State\label{alg::dynamic::update} $\textbf{A}[b]=\textbf{A}[b]\cdot(1-r_i)+\textbf{A}[b+2^{\ell-i}]\cdot r_i$
% 				\EndFor
% 				\For{$t\in\{0,1\}$} 
% 					\State\label{alg::dynamic::sum} Compute $\sum_{b\in\binary^{\ell-i}}f(r_1,\ldots, r_{i-1}, t, b)$ and send to $\V$.
% 				\EndFor
% 			\EndFor
% 			\EndProcedure
% 		\end{algorithmic}
% 	\end{algorithm}
% %	\vspace{-.5in}
% \end{figure}

We note here that applying Algorithm~\ref{alg:sumcheck} \textsf{SumCheck} for this particular class of polynomials would lead to quadratic prover time. This is because $f_1$ has $2^{2\ell}$ variables to sum on yielding $O(2^{2\ell})$ complexity. However, one could take advantage of the sparsity of $f_1$: the prover can store only the $O(2^\ell)$ non-zero values. This is exactly the approach used in many prior work~\cite{CMT,wahby2017full,vram}. However, with this approach, the number of nonzero values that must be considered in Step~\ref{step:consider_b} is always at most $2^{\ell}$ since it is not guaranteed that this number will reduce to half (i.e., to $2^{\ell-i}$) after every update in Step~\ref{alg::dynamic::update} of Algorithm~\ref{alg:evaluate}. Therefore, the overall complexity becomes $O(\ell \cdot 2^\ell)$. 

In this section we effectively reduce this bound to $O(2^\ell)$. Our protocol divides the sumcheck into two phases: the first $\ell$ rounds bounding the variables of $x$ to a random point $u$, and the last $\ell$ rounds bounding the variables of $y$ to a random point $v$. The central idea lies in rewriting Equation~\ref{eq:linearsc} as follows

\begin{eqnarray}
 \sum\nolimits_{x,y\in\binary^\ell}f_1(g,x,y)f_2(x)f_3(y)&=&\sum\nolimits_{x\in\binary^\ell}f_2(x)\sum\nolimits_{y\in\binary^\ell}f_1(g,x,y) f_3(y)\nonumber\\
&=& \sum\nolimits_{x\in\binary^\ell}f_2(x)   h_g(x)\nonumber\,,
\end{eqnarray}
where $h_g(x) = \sum_{y\in\binary^\ell}f_1(g,x,y) f_3(y)$. 


\subsubsection{Phase one.} 
To compute the sumcheck messages for the first $\ell$ rounds we  call $$\textsf{SumCheckProduct}(h_g(x),f_2(x),u_1,\ldots,u_\ell)$$ since functions $h_g$ and $f_2$ can be viewed as functions only in $x$---$y$ can be considered constant (it is always summed on the hypercube). By Lemma~\ref{main_lemma_complexity} this will take $O(2^\ell+T)$ time where $T$ is the time required to compute the bookkeeping tables of $h_g$ and $f_2$. We now show how to compute the bookkeeping tables in linear time.

\smallskip
\noindent{\underline{\emph{Computing the bookkeeping tables:}} \\Computing the bookkeeping table for $f_2$  in $O(2^\ell)$ time is trivial, since $f_2$ is a multilinear extension of an array and therefore the evaluations on the hypercube are known. Computing the bookkeeping table for $h_g$ in $O(2^\ell)$ time is more challenging but we can leverage the sparsity of $f_1$. Before we present our main result (see Theorem~\ref{final_time}), let us define $\textbf{G}[z]$ for $z\in \binary^\ell$, with respect to the fixed point $g$, as $\prod_{i=1}^\ell ((1-g_i)(1-z_i)+g_iz_i))$. We now have the following lemmata:

\babis{pls write formal proofs of the lemmata below}

\begin{lemma}\label{lemma_g}
There exists an algorithm that runs in $O(2^\ell)$ time that computes $\textbf{\emph{G}}[z]$ for all $z\in \binary^\ell$.
\begin{proof}


		\begin{algorithmic}[1]
			\Procedure{{$\textbf{G}\leftarrow$  \sf Precompute}}{$g$}    \Comment{$g\in\F^\ell$, $\textbf{G}$ is an array of size $2^\ell$.}
			\State Set $\textbf{G}[0] = 1$
			\For{$i=0,\ldots,\ell-1$}
			\For{$b\in\binary^i$}
			\State $\textbf{G}[b,0] = \textbf{G}[b]\cdot(1-g_{i+1})$ \Comment{$g_{i+1}$ is the $(i+1)$-th element in $g$.}
			\State $\textbf{G}[b,1] = \textbf{G}[b]\cdot g_{i+1}$
			\EndFor
			\EndFor
			\EndProcedure
		\end{algorithmic}
	
\babis{pls provide alg here and proof}
\end{proof}
\end{lemma}
\begin{lemma}\label{lemma_h_g}
Let $\mathcal{N}_x$ be the set of $(z,x,y)\in \binary^{3\ell}$ such that $f_1(g,x,y)$ is non-zero. Then it is
$h_g(x) = \sum_{(z,x,y)\in \mathcal{N}_x} \textbf{\emph{G}}[z]\cdot f_3(y)$.
\end{lemma}
\begin{proof}
\babis{pls provide proof here}
\end{proof}
\begin{lemma}\label{final_time}
When using the formula from Lemma~\ref{lemma_h_g} to initialize the bookkeeping table for $h_g$, Algorithm $\textsf{\emph{SumCheckProduct}}(h_g(x),f_2(x),u_1,\ldots,u_\ell)$ runs in $O(2^\ell)$ time.
\end{lemma}
\begin{proof}
Since $f_1$ has $O(2^\ell)$ non-zero terms it follows that $\sum |N_x|=O(2^\ell)$. Also since by Lemma~\ref{lemma_g}, $\textbf{G}[z]$ can be pre-computed in $O(2^\ell)$ time, it follows that the bookkeeping table for $h_g$ can be computed in $O(2^\ell)$ time.
\end{proof}

\subsubsection{Phase two.} At this point, all variables in $x$ have been bounded to random numbers $u$. In the second phase, the equation to sum on becomes 
\[
\sum\nolimits_{y\in\{0,1\}^\ell}f_1(g,u,y)f_2(u)f_3(y)
\]
Note here that $f_2(u)$ is merely a single value which we already computed in phase one. Both $f_1(g,u,y)$ and $f_3(y)$ are polynomials on $y$ with $\ell$ variables. Similar to phase one, to compute the messages for the last $\ell$ rounds we can call 
$$\textsf{SumCheckProduct}(f_1(g,u,y) ,f_3(y)\cdot f_2(u) ,v_1,\ldots,v_\ell)\,.$$ 
\smallskip
\noindent{\underline{\emph{Computing the bookkeeping table for $f_1$:}} \\
It now remains to compute the bookkeeping table for $f_1(g,u,y)$ efficiently. Again, we define $\textbf{U}[x]$ for $x\in \binary^\ell$, with respect to the fixed point $u$ (previous randomness), as $\prod_{i=1}^\ell ((1-u_i)(1-x_i)+u_ix_i)$. Note that by Lemma~\ref{lemma_g}, $\textbf{U}[x]$ for $x\in \binary^\ell$ can be computed in $O(2^\ell)$ time. Similarly we now have the following lemma.
\begin{lemma}\label{lemma_f_1}
Let $\mathcal{N}_x$ be the set of $(z,x,y)\in \binary^{3\ell}$ such that $f_1(g,x,y)$ is non-zero. Then it is
$f_1(z,x,y) = \sum_{(z,x,y)\in \mathcal{N}_x} \textbf{\emph{G}}[z] \cdot \textbf{\emph{U}}[x]$.
\end{lemma}
\begin{proof}
\babis{pls provide proof}
\end{proof}
\begin{lemma}\label{final_time_2}
When using the formula from Lemma~\ref{lemma_f_1} to initialize the bookkeeping table for $f_1$, Algorithm $\textsf{\emph{SumCheckProduct}}(f_1(g,u,y) ,f_3(y)\cdot f_2(u) ,v_1,\ldots,v_\ell)$ runs in $O(2^\ell)$ time.
\end{lemma}
\begin{proof}
Follows from Lemma~\ref{lemma_g} and Lemma~\ref{lemma_f_1}---as in Lemma~\ref{final_time}.
\end{proof}

We now summarize the final linear-time algorithm for computing the prover messages for the sumcheck protocol on GKR functions. See Algorithm~\ref{final_alg} $\textsf{SumCheckGKR}$.
\begin{theorem}
Algorithm $\textsf{\emph{SumCheckGKR}}$ runs in $O(2^\ell)$ time.
\end{theorem}
\begin{proof}
Follows from Lemmata~\ref{final_time} and~\ref{final_time_2}.
\end{proof}

\begin{figure}
\begin{algorithm}[H]
		\caption{\label{final_alg}$\{a_1,\ldots,a_{2\ell}\}\leftarrow \textsf{SumCheckGKR}(f_1,f_2,f_3,u_1\ldots,u_\ell,v_1,\ldots,v_\ell,g)$}\label{alg:sumcheckgkr}
		 \textbf{Input:} Multilinear extensions $f_1(z,x,y)$ (with $O(2^\ell)$ non-zero entries), $f_2(x)$ and $f_3(y)$, randomness $u_1,\ldots,u_\ell$ and $v_1,\ldots,v_\ell$ and point $g$;\\
    \textbf{Output:} 
    $2\ell$ sumcheck messages for $\sum\nolimits_{x,y\in\binary^\ell}f_1(g,x,y)f_2(x)f_3(y)$;
   
		\begin{algorithmic}[1]
\State $\{a_1,\ldots,a_\ell\}\leftarrow \textsf{SumCheckProduct}(\sum_{y\in\binary^\ell}f_1(g,x,y) f_3(y),f_2(x),u_1,\ldots,u_\ell)$
\State $\{a_{\ell+1},\ldots,a_{2\ell}\}\leftarrow \textsf{SumCheckProduct}(f_1(g,u,y) ,f_3(y)\cdot f_2(u) ,v_1,\ldots,v_\ell)$
%\State $\textsf{SumCheckProduct}(h_g,f_2,u_1,\ldots,u_\ell)$
%\mathcal{F}\leftarrow \textsf{FunctionEvaluations}(f,r_1,\ldots,r_\ell)$$
%\State $\mathcal{G}\leftarrow \textsf{FunctionEvaluations}(g,r_1,\ldots,r_\ell)$

							\State \textbf{return} $\{a_1,\ldots,a_{2\ell} \}$
		\end{algorithmic}
	\end{algorithm}
	
\end{figure}





 


\subsubsection{Generalizations of our technique.}

Our technique can be extended to sumchecks of the general type

\[
\sum\nolimits_{x_1, x_2,\ldots, x_c\in\binary^c}f_0(g,x_1, x_2,\ldots, x_c)f_1(x_1)f_2(x_2)...f_c(x_c)\, ,
\]
where $c$ is a constant, functions $f_i$ are multilinear and $f_0()$ is sparse and consists of linearly-many nonzero monomials. We divide the protocol into $c$ phases similarly as above. This generalization captures the sumcheck in the original GKR paper with identity polynomials (see~\cite{GKR}), and our new algorithms also improve the prover time of this to linear.





















\subsection{Putting everything together}

The sumcheck protocol in GKR given by Equation~\ref{eq:GKR} can be decomposed into several instances that has the form of Equation~\ref{eq:linearsc} presented in the previous section. The term $$\sum_{x,y\in\binary^{s_{i+1}}}\tmult_{i+1}(g,x,y)(\tV_{i+1}(x)\tV_{i+1}(y))$$ is exactly the same as Equation~\ref{eq:linearsc}.  The term $\sum_{x,y\in\binary^{s_{i+1}}}\tadd_{i+1}(g,x,y)(\tV_{i+1}(x)+\tV_{i+1}(y))$ can be viewed as: 
\[
\sum_{x,y\in\binary^{s_{i+1}}}\tadd_{i+1}(g,x,y)\tV_{i+1}(x)+\sum_{x,y\in\binary^{s_{i+1}}}\tadd_{i+1}(g,x,y)\tV_{i+1}(y)
\]
The first sum can be computed using the same protocol in Algorithm~\ref{final_alg} without $f_3(y)$, and the second sum can be computed without $f_2(x)$. The complexity for both cases remains linear. Due to linearity of the sumcheck protocol, the prover can execute these 3 instances simultaneously in every round, and sum up the individual messages and send them to the veriifer.



\paragraph{Combining two claims.} After the sumcheck in the GKR protocol is completed, as described in Section~\ref{subsec::GKR}, the prover and the verifier need to combine the two claims about $\tV_{i+1}$ received at the end of the sumcheck protocol to one to avoid the exponential blow-up. There are two ways to combine the two claims and we show how to do each of them in linear time. 

The second approach using random linear combinations is rather straight forward. After the output layers, $\P$ and $\V$ execute sumcheck protocol on Equation~\ref{eq:randomGKR} instead of Equations~\ref{eq:GKR}, which still satisfies the properties of Equation~\ref{eq:linearsc}. One could view it as 6 instances of Equation~\ref{eq:linearsc} and the prover time is still linear. Moreover, there is a better way to further improve the efficiency. Taking $\sum_{x, y \in\binary^{s_{i+1}}}(\alpha_i\tmult_{i+1}(u,x,y)+\beta_i\tmult_{i+1}(v,x,y))\tV_{i+1}(x)\tV_{i+1}(y)$ as an example, in Algorithm~\ref{alg::phase1}, the prover runs $\mathsf{Precompute}$ twice on $u$ and $v$ to generate two arrays ($\textbf{G}_1$ and $\textbf{G}_2$), and sets $\textbf{G}[b]=\alpha_i \textbf{G}_1[b] + \beta_i\textbf{G}_2[b]$ for all $b$. The rest of the algorithms remains the same. This only incurs a small overhead in practice in our implementation, compared to the original algorithm on Equation~\ref{eq:linearsc}.

Though with the approach above we already have a linear prover GKR protocol, the technique to condense two points to one proposed in the original GKR protocol~\cite{GKR} may still be interesting in some scenarios (e.g., in our implementation, we use this approach in the last layer and only make one query to the multi-linear extension of the input, which is more efficient practice). We present an algorithm to reduce the prover time of this approach to linear in Appendix~\ref{app:onepoint}.





\ignore{
	\subsubsection{Linear Prover Time Sumcheck}
	We will follow the CMT protocol, and improve the performance of sumcheck and the performance of combining two points. We will break the protocol into two parts, the first part deal with queries about $u$, and the second part will deal with queries about $v$.
	\subsubsection{Part One} In this part, we will deal with queries in first $s_{i+1}$ rounds.
	\paragraph{Review the sumcheck}
	In this subsection, we focus on answering the sumcheck queries. In the first round, the verifier asks the prover to give a univariate function: 
	
	$$f_{i, 1}(x_1)=\sum_{u_{k} \in \{0, 1\}, v \in \{0, 1\}^{s_{i+1}}}\tilde{mult}_{i}(g, \{x_1, u_{2},..., u_{s_{i+1}}\}, v)(\tV_{i+1}(x_1, u_{2},..., u_{|u|})\tV_{i+1}(v)),$$
	where $v$ is a binary vector in $\{0, 1\}^{s_{i+1}}$, $\{x_1, u_{2},..., u_{s_{i+1}}\}$ is the representation of $u$.
	
	In the $k$-th round where $2\le k\le s_{i+1}$, the verifier asks the prover to give a univariate function:
	\begin{align*}
	f_{i,k}(x_k)=\sum_{u_k \in \{0, 1\}, v \in \{0, 1\}^{s_{i+1}}}\tilde{mult}_{i}(g, \{r_1,r_2,...,r_{k-1},x_k, u_{k+1},..., u_{s_{i+1}}\}, v)\times\\
	(\tV_{i+1}(r_1,r_2,...,r_{k-1},x_k, u_{k+1},..., u_{s_{i+1}})\tV_{i+1}(v))
	\end{align*}
	where $v$ is a binary vector in $\{0, 1\}^{s_{i+1}}$, $\{r_1,r_2,...,r_{k-1},x_k, u_{k+1},..., u_{s_{i+1}}\}$ is the representation of $u$.
	
	\paragraph{The Definition of Building Block}
	In the first round, we calculate two arrays to help speed up calculation, where each array element is a pair $(a, b)$ representing a linear function $ax+b$.
	
	The first array is $mult_1^1$, where $mult_1^1[p]$ is a pair $(a, b)$ representing a linear function as follows:
	$${mult}_1^1[p]\overset{def}{=}\sum_{v\in \{0,1\}^{s_{i+1}}}\tilde{mult}_i(g, \{x_1, p\}, v)\tV_{i+1}(v),$$
	here $p$ is a $s_{i+1}-1$ bits binary number. $\{x_1, p\}$ is the representation of $u$. Similarly we define our second array ${V}_1^1[p]$ as follows:
	$$V_1^1[p]\overset{def}{=}\tV_i(\{x_1, p\})$$
	
	We will treat both arrays as a linear function or a pair of field elements interchangeably, for example ${mult}_1^1[p](x)$ means we treat it as a linear function, and ${mult}_1^1[p].a, {mult}_1^1[p].b$ means we treat it as a pair.
	
	Similarly we define arrays that used in $k$-th round as follows:
	\begin{definition}[Linear Function Array Part One]
		
		The definition for $k=1$ is the statement above, for $k\ge 2$
		\begin{enumerate}
			\item ${mult}_k^1[p]\overset{def}{=}\sum_{v\in \{0, 1\}^{s_{i+1}}}\tilde{mult}_i(g, \{r_1, ..., r_{k-1}, x_k, p\}, v)\tV_{i+1}(v)$
			\item ${V}_k^1[p]\overset{def}{=}\tV_i(\{r_1, ..., r_{k-1}, x_k, p\})$
			\item Where $p$ is a $s_{i+1}-k$ bits binary number and $\{r_1, ..., r_{k-1}, x_k, p\}$ is the representation of $u$.
		\end{enumerate}
	\end{definition}
	
	\paragraph{Initialize Arrays}
	We will try to initialize ${mult}_1^1, {V}_1^1$. And we will calculate next arrays using these arrays.
	
	For ${V}_1^1$, we can scan through the circuit and get all values of $\tV_{i+1}(u)$ when $u \in \{0, 1\}^{s_{i+1}}$, and we have the following equations:
	\begin{align*}
	{V}_1^1[p](0)=\tV_{i+1}(0||p)\\
	{V}_1^1[p](1)=\tV_{i+1}(1||p)
	\end{align*}
	We can solve for ${V}_1^1[p]$ easily.
	
	For ${mult}_1^1$, the idea is the same as ${V}_1^1$, but it's non-trivial to calculate $\sum_{v\in \{0,1\}^{s_{i+1}}}\tilde{mult}_{i+1}(g, u, v)\tV_{i+1}(v)$ for every binary $u$ in linear time, since we need to calculate $\tilde{\beta}_{s_{i}}(g, g')$ part in $\tilde{mult}_{i+1}(g, u, v)$. Instead enumerate every binary $u$ to initialize the array, we can enumerate $g'$ instead. And accumulate the contribution of $(g', u', v')$ to $\sum_{v\in \{0,1\}^{s_{i+1}}}\tilde{mult}_{i+1}(g, u', v)\tV_{i+1}(v)$. We will use a depth first search to enumerate every $g'$ bit by bit. The detailed algorithm is shown in Algorithm \ref{alg::premult}.
	\begin{figure}[p]
		\begin{algorithm}[H]
			\label{alg::premult}
			\caption{Preprocess ${mult}_1^1, {V}_1^1$}
			\begin{algorithmic}[1]
				\parState{Assuming we have global access to $g$, $s_i$, $s_{i+1}$, which is reasonable since prover knows these values, and $g[k]$ means the $k$-th field element of $g$, starting from $0$ since we are writing pseudo-code}
				\Procedure{{\sf DFS}}{$A$, $g'$, $depth$, $Value$}
				\parState{Note $A$, $g'$ is the pointer to the array, any change to $A$ or $g'$ will change it globally.}
				\parState{In this function, we will recurse on the bits of $g$}
				\If {$depth=s_{i}$} \Comment{We have enumerate enough bits}
				\State Let $u', v'$ is input gates to $g'$
				\State Find $\tV_{i+1}(v')$ in circuit.
				\State $A[u'] = A[u'] + \tV_{i+1}(v')\times Value$
				\Else
				\State set $g'[depth]=0$
				\State Call {\sf DFS}($A$, $g'$, $depth+1$, $Value\times(1-g[depth])$)
				\State set $g'[depth]=1$
				\State Call {\sf DFS}($A$, $g'$, $depth+1$, $Value\times g[depth]$)
				\EndIf
				\EndProcedure
				\Procedure{{\sf InitializeMult}}{}
				\State Let array ${mult}_1^1$ be filled with zeros.
				\parState{Since calculate $\sum_{v\in \{0,1\}^{s_{i+1}}}\tilde{mult}_{i+1}(g, u, v)\tV_{i+1}(v)$ for every binary $u$ is enough to initialize array ${mult}_1^1$, we will call a subroutine to initialize every binary $u$, and store the result into array $A$.}
				\State Initialize array $A$ with zeros.
				\State let $g'$ be a vector of $s_{i+1}$ bits.
				\State Call {\sf DFS}($A$, $g'$, $0$, $1$)
				\For{each $p \in \{0, 1\}^{s_{i+1}-1}$}
				\parState{By solving the linear equations, we can get the following statements}
				\State ${mult}_1^1[p].b=A[0||p]$
				\State ${mult}_1^1[p].a=A[1||p]-A[0||p]$
				\EndFor
				\EndProcedure
			\end{algorithmic}
		\end{algorithm}
	\end{figure}
	
	\paragraph{Answer Queries}
	The answer to the first query is the following univariate function:
	
	$$\sum_{p}{mult}_1^1[p](x)\times{V}_1^1[p](x),$$
	
	It's easy to get this result by doing some transformation on the original equation.
	
	We reduce these arrays to the second round using the following way
	
	\begin{enumerate}
		\item By definition, ${mult}_2^1[p'](0)={mult}_1^1[0||p'](r_1)$ and ${mult}_2^1[p'](1)={mult}_1^1[1||p'](r_1)$
		\item By definition, ${V}_2^1[p'](0)={V}_1^1[0||p'](r_1)$ and ${V}_2^1[p'](1)={V}_1^1[1||p'](r_1)$
		
		\item Since both ${mult}_2^1, {V}_2^1$ are linear equations, we can solve the ${mult}_2^1, {V}_2^1$ by solving linear equations.
		\item By solving linear equations we found that ${mult}_2^1[p'].b={mult}_1^1[0||p'](r_1)$ and ${mult}_2^1[p'].a={mult}_1^1[1||p'](r_1)-{mult}_1^1[0||p'](r_1)$
	\end{enumerate}
	
	The answer to the second round is 
	
	$$\sum_{p'}{mult}_2^1[p']\times{V}_2^1[p']$$
	
	We define arrays for the $k$-th round ($k\ge 2$) in the similarly using the result from $k-1$-th round, and solving the linear equation.
	
	The answer to the $k$-th round query is 
	$$\sum_{p}{mult}_k^1[p]\times{V}_k^1[p]$$
	
	\begin{theorem} For every round, the algorithm above correctly answered the query. And the running time of the algorithm runs in time $O(\max(2^{s_i}, 2^{s_{i+1}}))$.
	\end{theorem}
	
	\begin{proof}
		It's trivial to see that ${mult}_k^1, {V}_k^1$ are computed correctly. 
		
		For time complexity part, ${mult}_k^1, {V}_k^1$ are computed in linear time since Algorithm \ref{alg::premult} runs in linear time, and for $k$-th layer, the size of ${mult}_k^1$ is half size of ${mult}_{k-1}^1$, by total size of these arrays is linear to the circuit size.
		
		The answer to the verifier is correct by the definition of ${mult}_k^1, {V}_k^1$.
	\end{proof}
	
	\subsubsection{Part two}
	In this part, we will deal with next $s_{i+1}$ rounds. In these rounds, $g, u$ are fixed random vector with $s_{i}, s_{i+1}$ random field elements respectively.
	
	\paragraph*{Initialize Arrays}
	We define two arrays ${mult}_k^2, {V}_k^2$ analogue to ${mult}_k^1, {V}_k^1$.
	
	\begin{definition}[Linear Function Array Part Two]
		For $k=1$, we define 
		\begin{enumerate}
			\item ${mult}_1^2[p] = \tilde{mult}_i(g, u, \{x_1, p\})\tV_{i+1}(u)$
			\item ${V}_1^2[p] = \tV_{i+1}(\{x_1, p\})$
		\end{enumerate}
		For $k\ge 2$, we define
		\begin{enumerate}
			\item ${mult}_k^2[p]\overset{def}{=}\tilde{mult}_i(g, u, \{r_1, ..., r_{k-1}, x_k, p\})\tV_{i+1}(u)$
			\item ${V}_k^2[p]\overset{def}{=}\tV_i(\{r_1, ..., r_{k-1}, x_k, p\})$
			\item Where $p$ is a $s_{i+1}-k$ bits binary number and $\{r_1, ..., r_{k-1}, x_k, p\}$ is the representation of $v$.
		\end{enumerate}
	\end{definition}
	
	As we discussed in Part One, we only need to calculate all the values of ${mult}_k^2, {V}_k^2$. By the definition of $\tilde{mult}_i(g, u, v)\overset{def}{=}\sum_{g', u', v' \in G_{i, mult}}\tilde{\beta_{s_i}}(g, g')\tilde{\beta_{s_{i+1}}}(u, u')\tilde{\beta_{s_{i+1}}}(v, v')$. We found that $\tilde{mult}_i$ is composed by three separate functions. Since $g, u$ are fixed random vector, we can preprocess $\tilde{\beta}_{s_i}(g, g')$ for every binary $g'$ and preprocess $\tilde{\beta}_{s_{i+1}}(u, u')$ for every binary $u'$. See the detailed algorithm in Algorithm \ref{alg::parttwo}.
	
	\begin{figure}[p]
		\begin{algorithm}[H]
			\label{alg::parttwo}
			\caption{Preprocess $mult_1^2, V_1^2$}
			\begin{algorithmic}[1]
				\parState{Array/Vector parameters are passed by pointer, any change to the array will effect the array globally}
				\Procedure{{\sf DFS}}{$A, x, randVec, depth, maxDepth, value$}
				\If{$depth=maxDepth$}
				\State $A[x]=value$
				\Else
				\State set $x[depth]=0$
				\State Call DFS($A$, $x$, $depth + 1$, $value \times (1-randVec[depth])$)
				\State set $x[depth]=1$
				\State Call DFS($A$, $x$, $depth + 1$, $value \times randVec[depth]$)
				\EndIf
				\EndProcedure
				\Procedure{{\sf PreprocessBeta}}{$BetaMult, BetaV$}
				\State let $g', u'$ be zero $s_{i}, s_{i+1}$ length vector
				\State Call {\sf DFS}($BetaMult$, $g'$, $g$, $0$, $s_{i}$, $1$)
				\State Call {\sf DFS}($BetaV$, $u'$, $u$, $0$, $s_{i + 1}$, $1$)
				\EndProcedure
				\Procedure{{\sf Preprocess}}{${Mult}_1^2, {V}_1^2$}
				\State Let $BetaMult, BetaV$ be a array with length $2^{s_{i}}, 2^{s_{i+1}}$ respectively
				\State Call {\sf PreprocessBeta}($BetaMult$, $BetaV$)
				\State Let $MultBinaryU$ be a array with $2^{s_{i+1}}$ field elements, initially set to $0$.
				\parState{The array $MultBinaryU[v'] \overset{def}{=}\tilde{mult}_i(g, u, v')\tV_{i+1}(u)$}, we will show that how to compute this array in this For loop.
				\For{Each $v' \in \{0, 1\}^{s_{i+1}}$}
				\For{Each $(g', u')$ that is connected to $v'$ in the circuit}
				\State $MultBinaryU[v'] += BetaMult[g'] \times BetaV[u'] \times \tV_{i+1}[u]$
				\parState{Since $u$ is a constant, $\tV_{i+1}[u]$ is a constant all the time as well, we can obtain the value from the result of Part One (It equals to $V_{s_{i+1}-1}^1[0](r_{s_{i+1}})$ by the definition of $V_{k}^1$).}
				\EndFor
				\EndFor
				
				\For {each $p \in \{0, 1\}^{s_{i+1}-1}$}
				\parState{By solving the linear equations , we can get the following statements}
				\State $Mult_1^2[p].b = MultBinaryU[0||p]$
				\State $Mult_1^2[p].a = MultBinaryU[1||p]-MultBinaryU[0||p]$
				\parState{$\tV_{s_{i+1}}[v']$ is the value directly from the circuit, we assume it's preprocessed into a array.}
				\State $V_1^2[p].b = \tV_{s_{i+1}}[0||p]$
				\State $V_1^2[p].a = \tV_{s_{i+1}}[1||p]-\tV_{s_{i+1}}[0||p]$
				\EndFor
				\EndProcedure
			\end{algorithmic}
		\end{algorithm}
	\end{figure}
	
	\paragraph*{Answer Queries}
	The answer to the first query is the following univariate function:
	
	$$\sum_{p}mult_{1}^2[p](x)\times V_1^2[p](x)$$
	
	It's easy to check that this summation is equals to the original sumcheck summation.
	
	To answer $k$-th query ($k\ge 2$), we suppose we have answered the $k-1$-th query and generated arrays $mult_{k-1}^2, V_{k-1}^2$, we generate $mult_{k}^2, V_{k}^2$ and answer the $k$-th query in the following way:
	
	\begin{enumerate}
		\item By definition, $\forall p \in {\{0, 1\}^{s_{i+1}-k}}$, $mult_{k}^2[p](0)=mult_{k-1}^2[0||p](r_{k-1}), mult_{k}^2[p](1)=mult_{k-1}^2[1||p](r_{k-1})$
		\item By definition, $\forall p \in {\{0, 1\}^{s_{i+1}-k}}$, $V_{k}^2[p](0)=V_{k-1}^2[0||p](r_{k-1}), V_{k}^2[p](1)=V_{k-1}^2[1||p](r_{k-1})$
		\item Since $mult_{k}^2[p], V_{k}^2[p]$ are linear function, we can solve the equations above. We have the following results.
		\item $\forall p \in {\{0, 1\}^{s_{i+1}-k}}$, $mult_{k}^2[p].b = mult_{k-1}^2[0||p](r_{k-1}), mult_{k}^2[p].a = mult_{k-1}^2[1||p](r_{k-1})-mult_{k-1}^2[0||p](r_{k-1})$
		\item $\forall p \in {\{0, 1\}^{s_{i+1}-k}}$, $V_{k}^2[p].b = V_{k-1}^2[0||p](r_{k-1}), V_{k}^2[p].a = V_{k-1}^2[1||p](r_{k-1})-V_{k-1}^2[0||p](r_{k-1})$
		\item For $k$-th round, the answer to the query is $\sum_{p} mult_{k}^2[p](x)\times V_{k}^2[p](x)$
	\end{enumerate}
	
	\begin{theorem} The algorithm above correctly answered queries of last $s_{i+1}$ rounds, and runs in time $O(\max(2^{s_{i}}, 2^{s_{i+1}}))$.
	\end{theorem}
	
	\begin{proof}
		Since we only need to scan through the circuit, the time complexity is linear for initialize $mult_{1}^2, V_1^2$. The size of $mult_{k}^2, V_k^2$ is half of $mult_{k-1}^2, V_{k-1}^2$. The total size of $mult_{k}^2, V_k^2$ is linear to the size of $mult_1^2, V_1^2$, which is the circuit size. And to answer the query, we only need to scan through these arrays. The total time complexity is linear to the circuit size.
		
		If $mult_k^2, V_k^2$ are generated correctly, the answer to the query is correct by definition.
		
		$V_1^2$ is correct since it's equal to the circuit value. $mult_1^2$ is correct if and only if $MultBinaryU$ is generated correctly. $\forall g'$, $BetaMult[g']$ is correct because we calculated it bit by bit according to definition in $DFS$ part. And so does $BetaV[u']$. By definition 
		\begin{align*}
		MultBinaryU[v']&\overset{def}{=}\tilde{mult}_{i}(g, u, v')\tV_{i+1}(u)
		\\&=\sum_{v=v', (g', u', v) \in G_{i, mult}}\tilde{\beta}_{s_{i}}(g, g')\tilde{\beta}_{s_{i+1}}(u, u')\tilde{\beta}_{s_{i+1}}(v, v')\tV_{i+1}(u)
		\\&=\sum_{v=v', (g', u', v) \in G_{i, mult}}\tilde{\beta}_{s_{i}}(g, g')\tilde{\beta}_{s_{i+1}}(u, u')\tV_{i+1}(u)
		\end{align*}
		
		Since $BetaMult[g'], BetaV[u']$ are correct, we have $MultBinaryU$ is correct. Thus $mult_1^2$ is correct.
		
		To prove $mult_k^2, V_k^2$ is correct ($k \ge 2$). We assume $mult_{k-1}^2, V_{k-1}^2$ is correct. According to the definition of $mult_k^2$, $mult_k^2[p](0)=\tilde{mult}_i(g, u, {r_1, r_2,...,r_{k-1}, 0, p})=mult_{k-1}^2[0||p](r_{k-1})$, $mult_k^2[p](1)=\tilde{mult}_i(g, u, {r_1, r_2,...,r_{k-1}, 1, p})=mult_{k-1}^2[1||p](r_{k-1})$, by solving the linear equation, we can get the right value of $mult_k^2[p]$. And we have a similar argument of $V_k^2$.
	\end{proof}
}