\newpage

\appendix

\section{Cryptographic Assumptions}\label{app:assume}

Our constructions use the following assumptions.


\begin{assumption}[$q$-Strong Bilinear Diffie-Hellman]
	\label{asp::qSDH}
	For any probabilistic polynomial time (PPT) adversary $\mathcal{A}$, the following holds:
	
	\[\Pr\left[ \begin{aligned}
	&\mathsf{bp} \leftarrow \mathsf{BilGen}(1^\lambda) & \\
	&s \overset{R}{\leftarrow} \mathbb{Z}^{*}_{p} & : (x, e(g, g)^{\frac{1}{s+x}}) \leftarrow \mathcal{A}(1^\lambda, \sigma)\\
	&\sigma = (\mathsf{bp}, g^s, ..., g^{s^q})
	\end{aligned} \right] \le \negl{(\lambda)}\]
\end{assumption}

The second assumption is a generalization of the $q$-PKE assumption~\cite{groth2010short} to multivariate polynomials, proposed in~\cite{zhang2017vsql,zkvpd}. Let $\mathcal {W}_ {\ell,d}$ be the set of all multisets of $\{1, . . . , \ell\}$ with the cardinality of each element being at most $d$. 

\begin{assumption}[$(d,\ell)$-Extended Power Knowledge of Exponent]
	\label{asp::dlEPKE}
	For any PPT adversary $\mathcal{A}$, there is a polynomial time algorithm $\mathcal{E}$ (takes the same randomness of $\mathcal{A}$ as input) such that for all benign auxiliary inputs $z \in \{0,1\}^{\poly({\lambda})}$ the following probability is negligible:
	{\footnotesize
	\[\Pr\left[ \begin{aligned}
	\mathsf{bp} \leftarrow \mathsf{BilGen}(1^\lambda) && \\
	s_1, ..., s_\ell, s_{\ell + 1}, \alpha \overset{R}{\leftarrow} Z_{p}^*, s_0=1 && \\
	\sigma_1 = (\{g^{\prod_{i\in W}s_i}\}_{W\in \mathcal{W}_{\ell, d}, g^{s_{\ell+1}}}) &&\hspace*{10pt} e(h, g^\alpha)=e(\tilde{h}, g)\\
	\sigma_2 = (\{g^{\alpha\prod_{i\in Ws_i}}\}_{W\in \mathcal{W}_{\ell, d}}, g^{\alpha s_{\ell+1}}) && : \prod_{W\in \mathcal{W}_{\ell, d}}g^{a_{W}\prod_{i\in W}s_i}g^{b{s_{\ell+1}}}\neq h\\
	\sigma = (\mathsf{bp}, \sigma_1, \sigma_2, g^{\alpha}) && \\
	\mathbb{G} \times \mathbb{G} \ni (h, \tilde{h}) \leftarrow \mathcal{A} \left(1^{\lambda}, \sigma, z\right)&& \\
	\left( a _ { 0 } , \dots , a _ { \left| \mathcal { W } _ { \ell , d } \right| } , b \right) \leftarrow \mathcal { E } \left( 1 ^ { \lambda } , \sigma , z \right) &&
	\end{aligned}\right] \le \negl{(\lambda)}\]
	}
\end{assumption}

\section{GKR protocol}\label{app:gkr}

%\begin{figure}[t!]
	\small{
		\centering{\centering
			\framebox{\parbox{.99\linewidth}{
					\begin{protocol}
						\label{protocol::GKR}
						Let $\mathbb{F}$ be a prime field. Let $C$: $\mathbb{F}^n\rightarrow \mathbb{F}^k$ be a $d$-depth layered arithmetic circuit. $\mathcal{P}$ wants to convince that $\mathsf{out}=C(\mathsf{in})$ where $\mathsf{in}$ is the input from $\V$, and $\mathsf{out}$ is the output. Without loss of generality, assume $n$ and $k$ are both powers of 2 and we can pad them if not.
						
						\begin{itemize}
							\item Define the multilinear extension of array $\mathsf{out}$ as $\tV_0$. $\V$ chooses a random $g \in \mathbb{F}^{s_0}$ and sends it to $\P$. Both parties compute $\tilde{V_0}(g)$.
							\item $\P$ and $\V$ run a sumcheck protocol on
							\[
							\tV_{0}(g^{(0)})=\sum_{x, y\in \binary^{s_{1}}}\tilde{mult}_{1}(g^{(0)}, x, y)(\tV_{1}(x)\tV_{1}(y))+\tilde{add}_{1}(g^{(0)},x,y)(\tV_{1}(x)+\tV_{1}(y))
							\]
							At the end of the protocol, $\V$ receives $\tV_1(u^{(1)})$ and $\tV_1(v^{(1)})$. $\V$ computes $\tmult_1(g^{(0)},u^{(1)},v^{(1)})$, $\tadd_1(g^{(0)},u^{(1)},v^{(1)})$ and checks that $\tmult_1(g^{(0)},u^{(1)},v^{(1)})\tV_1(u^{(1)})\tV_1(v^{(1)})+\tadd_1(g^{(0)},u^{(1)},v^{(1)})(\tV_1(u^{(1)})+\tV_1(v^{(1)}))$ equals to the last message of the sumcheck.
							
							\item For $i=1,...,d-1$:
							\begin{itemize}
								
								\item $\V$ randomly selects $\alpha^{(i)}, \beta^{(i)}\in\F$ and sends them to $\mathcal{P}$.
								\item $\P$ and $\V$ run the sumcheck on the equation\\
								
								$\alpha^{(i)}\dot{V}_i(u^{(i)})+\beta^{(i)}\dot{V}_i(v^{(i)})=$
								\begin{align*}
								\sum_{x, y\in \binary^{s_{i+1}}}&((\alpha^{(i)}\tilde{mult}_{i+1}(u^{(i)}, x, y)+\beta^{(i)}\tilde{mult}_{i+1}(v^{(i)}, x, y))(\tV_{i+1}(x)\tV_{i+1}(y))\\
								+&(\alpha^{(i)}\tilde{add}_{i+1}(u^{(i)}, x, y)+\beta^{(i)}\tilde{add}_{i+1}(v^{(i)}, x, y))(\tV_{i+1}(x)+\tV_{i+1}(y))\nonumber
								\end{align*}
								
								\item At the end of the sumcheck protocol, $\P$ sends $\V$ $\tV_{i+1}(u^{(i+1)})$ and $\tV_{i+1}(v^{(i+1)})$.
								
								
								\item $\V$ computes the following and checks if it equals to the last message of the sumcheck. For simplicity, let $Mult_{i+1}(x) = \tilde{mult}_{i+1}(x, u^{(i+1)}, v^{(i+1)})$ and $Add_{i+1}(x) = \tilde{add}_{i+1}(x, u^{(i+1)}, v^{(i+1)})$.
								\begin{align*}
								&(\alpha^{(i)}Mult_{i+1}(u^{(i)})+\beta^{(i)}Mult_{i+1}(v^{(i)})(\tV_{i+1}(u^{(i+1)})\tV_{i+1}(v^{(i+1)}))+\\
						        &(\alpha^{(i)}\tilde{Add}_{i+1}(u^{(i)})+\beta^{(i)}\tilde{Add}_{i+1}(v^{(i)})(\tV_{i+1}(u^{(i+1)})+\tV_{i+1}(v^{(i+1)}))
								\end{align*}
								If all checks in the sumcheck pass, $V$ uses $\tV_{i+1}(u^{(i+1)})$ and $\tV_{i+1}(v^{(i+1)})$ to proceed to the $(i+1)$-th layer. Otherwise, $\V$ outputs $\reject$ and aborts.
								
							\end{itemize}
							\item At the input layer $d$, $\V$ has two claims $\tV_{d}(u^{(d)})$ and $\tV_{d}(v^{(d)})$. $\V$ queries the oracle of evaluations of $\tV_d$ at $u^{(d)}$ and $v^{(d)}$ and checks that they are the same as the two claims. If yes, output $\accept$; otherwise, output $\reject$.
							
						\end{itemize}
	\end{protocol}}}}}
%\end{figure}

\section{Definition of zkVPD}\label{app:zkvpd}

\begin{definition}\label{def::zkvpd}
Let $\mathbb{F}$ be a finite field, $\mathcal{F}$ be a family of $\ell$-variate polynomial over $\mathbb{F}$, and $d$ be a variable-degree parameter. A zero-knowledge verifiable polynomial delegation scheme (zkVPD) consists of the following algorithms: $(\pp, \vp) \leftarrow \KeyGen(1^\lambda, \ell, d)$, $\comm \leftarrow \Commit(f, r_f, \pp)$, $\{\accept,\reject\}\leftarrow\CheckComm(\comm, \vp)$, $(y,\pi)\leftarrow\Open(f,t,r_f,\pp)$, $\{\accept,\reject\}\leftarrow\Verify(\comm,t,y,\pi,\vp)$, such that

\begin{itemize}
			\item \textbf{Perfect Completeness}
				For any polynomial $f \in \mathcal{F}$ and value $t$, the following probability is 1.
				\[\Pr_{r_f}\left[
					\begin{aligned}
						(\pp, \vp) \leftarrow \KeyGen(1^\lambda, \ell, d) && \\
						\comm \leftarrow \Commit(f, r_f, \pp) &:&  \CheckComm(\comm, \vp)=\accept \hspace*{5pt}\land \\
						(y, \pi) \leftarrow \Open(f, t, r_f, \pp) && \hspace*{10pt}\Verify(\comm, t, y, \pi, \vp)=\accept\\
					\end{aligned}
				\right]\]
			\item \textbf{Binding}
			For any PPT adversary $\mathcal{A}$ and benign auxiliary input $z_1, z_2$ the following probability is negligible of $\lambda$:
			{\footnotesize
			\[\Pr \left[
				\begin{aligned}
					(\pp, \vp) \leftarrow \KeyGen(1^\lambda, \ell, d) && \CheckComm(\comm^*, \vp)=\accept \hspace*{5pt}\land\\
					(\pi^*, \comm^*, y^*, state) \leftarrow \mathcal{A}(1^\lambda, z_1, \pp) &:& \Verify(\comm^*, t^*, y^*, \pi^*, \vp)=\accept \hspace*{5pt} \land\\
					(f^*, t^*, r_f^*) \leftarrow \mathcal{A}(1^\lambda, z_2, state, \pp) && \comm^*=\Commit(f^*, r_f^*, \pp) \hspace*{5pt} \land\\
					&& (y^*, \pi^*) = \Open(f^*, t^*, r_f^*, \pp) \hspace*{5pt} \land \\
					&& f^*(t^*) \neq y^*\\
				\end{aligned}
			\right]\]
			}
			\item \textbf{Zero Knowledge} For security parameter $\lambda$, polynomial $f$, adversary $\mathcal{A}$, and simulator $\S$, consider the following two experiments:
			{\footnotesize
				\begin{align*}
					\begin{minipage}{.48\linewidth}
						$\mathsf{Real}_{\A, f}(1^\lambda)$:
						\begin{enumerate}
							\item $(\pp, \vp) \leftarrow \KeyGen(1^\lambda, \ell, d)$
							%\item \text{Generate $r_f$ uniformly at random}
							\item $\comm \leftarrow \Commit(f, r_f, \pp)$
							\item $k\leftarrow \mathcal{A}(1^\lambda, \comm, \vp)$
							\item \text{For $i=1,...,k$ repeat}
							\begin{enumerate}
								\item $t_i \leftarrow \A(1^\lambda, \comm, y_1,...,y_{i-1}, \pi_1,\\ ..., \pi_{i-1}, \vp)$
								\item $(y_i, \pi_i) \leftarrow \Open(f, t_i, r_f, \pp)$
							\end{enumerate}
							\item $b \leftarrow \A(1^\lambda, \comm, (y_1, ..., y_k, \pi_1, ..., \pi_k), \vp)$
							\item \text{Output b}
						\end{enumerate}
					\end{minipage}
					\hspace*{5pt}\vline \hspace*{5pt}
					%\vline
					\begin{minipage}{.48\linewidth}
						$\mathsf{Ideal}_{\A, \S}(1^\lambda)$:
						\begin{enumerate}
							\item $(\comm, \pp, \vp, \sigma) \leftarrow \mathsf{Sim}(1^\lambda, \ell, d)$
							\item $k \leftarrow \A(1^\lambda, \comm, \vp)$
							\item \text{For $i=1,...,k$ repeat}:
							\begin{enumerate}
								\item $t_i \leftarrow \A(1^\lambda, \comm, y_1, ..., y_{i-1}, \pi_1,\\ ..., \pi_{i-1}, \vp)$
								\item $(y_i, \pi_i, \sigma) \leftarrow \mathsf{Sim}(t_i, \sigma, \pp)$
							\end{enumerate}
							\item $b \leftarrow \A(1^\lambda, \comm, (y_1, ..., y_k, \pi_1, ..., \pi_k), \vp)$
							\item \text{Output b}
						\end{enumerate}
					\end{minipage}
				\end{align*}
				}
				For any PPT adversary $\A$ and all polynomial $f\in\F$, there exists simulator $\S$ such that
				\[
				|\Pr[\mathsf{Real}_{\A, f}(1^\lambda)=1] - \Pr[\mathsf{Ideal}_{\A, \S}(1^\lambda)=1]|\le \negl(\lambda).
				\]
\end{itemize}

	
\end{definition}

\section{Condensing to One Point in Linear Time}\label{app:onepoint}


In this section, we present an algorithm to reduce two claims about $\tV_{i+1}$ to one in linear time. Recall that as described in Section~\ref{subsec::GKR}, in the $i$-th layer, after the sumcheck, the verifier receives two claims $\tV(u), \tV(v)$. (Again we omit the superscript and subscript of $i$ for the ease of interpretation.) She then defines a line $\gamma(x): \mathbb{F}\rightarrow\mathbb{F}^{s}$ such that $\gamma(0) = u, \gamma(1)=v$ and the prover needs to provide $\tV(\gamma(x))$, a degree $s$ univariate polynomial, to $\V$. If the prover computes it naively, which was done in all prior papers, it incurs $O(s2^{s})$ time, as it is equivalent to evaluating $\tV()$ at $s+1$ points. 

\begin{figure}[H]
	\begin{algorithm}[H]
		
		\caption{Compute $\tV(\gamma(x)) = \sum_{y\in\binary^s}I(\gamma(x), y)\tV(y)$}\label{alg::comb}
		\begin{algorithmic}[1]
			\State Initialize a binary tree $T$ with $s$ levels. We use $T_j[b]$ to denote the $b$-th node at level $j$.
			\For{$b\in\binary^s$}
				\State $T_s[b] = \tV(b)$.
				\State Multiply $T_s[b]$ with $b_s(c_s x+ d_s)+(1-b_s)(1-c_s x- d_s)$.
			\EndFor
			\For{$j = s-1, \ldots, 1$} 
				\For{$b\in\binary^{j}$}
					\State $T_j[b] = T_{j+1}[b,0]+T_{j+1}[b,1]$.
					\State $T_j[b] = T_j[b] \cdot (b_j(c_j x+ d_j)+(1-b_j)(1-c_j x- d_j))$. 
				\EndFor
			\EndFor
			\State Output $T_1[0]$.
		\end{algorithmic}
	\end{algorithm}
\end{figure}


In our new algorithm, we write $\tV(\gamma(x)) = \sum_{y\in\binary^s}I(\gamma(x), y)\tV(y)$, where $I(a,b)$ is an identity polynomial $I(a,b)=0$ iff $a=b$. This holds by inspection of both sides on the Boolean hypercube. We then evaluate the right side in linear time with a binary tree structure. The key observation is that the identity polynomial can be written as $I(a,b) = \prod_{j=1}^s (a_jb_j+(1-a_j)(1-b_j))$, and we can process one variable ($a_j,b_j$) at a time and multiply them together to get the final result. 

We construct a binary tree with $2^s$ leaves and initialize each leaf $b\in\binary^s$ with $\tV(b)$. As $\gamma(x)$ is a linear polynomial, we write it as $\gamma(x) = [c_1, \ldots, c_s]^T x+ [d_1, \ldots, d_s]^T$. At the leaf level, we only consider the last variable of $I(\gamma(x), y)$. For each leaf $b\in\binary^s$, we multiply the value with $b_s(c_s x+ d_s)+(1-b_s)(1-c_s x- d_s)$, the result of which is a linear polynomial. For a node $b\in\binary^j$ in the intermediate level $j$, we add the polynomials from its two children, and multiply it with $b_j(c_j x+ d_j)+(1-b_j)(1-c_j x- d_j)$, the part in $I$ that corresponds to the $j$-th variable. In this way, each node in the $j$-th level stores a degree $j$ polynomial. Eventually, the root is the polynomial on the right side of degree $s$, which equals to $\tV(\gamma(x))$. The algorithm is given in Algorithm~\ref{alg::comb}. 

To see the complexity of Algorithm~\ref{alg::comb}, both the storage and the polynomial multiplication at level $j$ is $O(s-j+1)$ in each node. So the total time is $O(\sum_{j=1}^s 2^j (s-j+1)) = O(2^s)$, which is linear to the number of gates in the layer.

An alternative way to interpret this result is to add an additional layer for each layer of the circuit in GKR relaying the values. That is, $$\tV_{i}(g) = \sum_{x\in\binary^{s_i}}I(g,x)\tV_{i+1}(x),$$ where $\tV_i = \tV_{i+1}$. Then when using the random linear combination approach, the sumcheck is executed on $$\alpha\tV_{i}(u)+\beta\tV_i(v) = \sum_{x\in\binary^{s_i}}(\alpha I(u,x)+\beta I(v,x))\tV_{i+1}(x).$$
At the end of the sumcheck, the verifier receives a single claim on $\tV_{i+1} = \tV_{i}$. The sumcheck can obviously run in linear time, and the relay layers do not change the result of the circuit. This approach is actually the same as the condensing to one point in linear time above conceptually. 



\section{Proof of Theorem~\ref{thm:zksc}}\label{app:proofsc}

\begin{proof}
	
	We build the simulator $\S$ as following.
	
	\begin{enumerate}
		
		\item $\S$ selects a random polynomial $g^*(x_1,\ldots,x_\ell) = a^*_{0} + g^*_1(x_1) + g^*_2(x_2) + \cdots + g^*_\ell(x_\ell)$, where $g^*_i(x_i) = a^*_{i,1}x_i + a^*_{i,2}x_i^2 + \cdots + a^*_{i,d}x_i^d$. $\S$ sends $H$, $G^* = \sum\limits_{x_1, x_2, \cdots, x_\ell \in \binary} g^*(x_1, x_2, \cdots, x_\ell)$ and $\comm_{g^*} = \Commit(g^*)$ to $\V$.
		
			
		\item $\S$ receives $\rho \neq 0$ from $\V^*$.
		\item $\S$ selects a polynomial $f^*:\F^\ell\rightarrow\F$ with variable degree $d$ uniformly at random conditioning on $\sum\limits_{x_1, x_2, \cdots, x_\ell \in \{0, 1\}}f^*(x_1, x_2, \cdots, x_\ell) = H$. $\S$ then engages in a sumcheck protocol with $\V$ on  $H+\rho G^* = \sum\limits_{x_1, x_2, \cdots, x_l \in \{0, 1\}}(f^*(x_1, x_2, \cdots, x_\ell)+\rho g^*(x_1, x_2, \cdots, x_\ell))$
		
		\item Let $r \in \F^\ell$ be the point chosen by $\V^*$ in the sumcheck protocol. $\S$ runs $(g^*(r), \pi)\leftarrow\Open(g^*,r)$ and sends them to $\V$.
		
	\end{enumerate} 
	
	As both $g$ and $g^*$ are randomly selected, and the zkVPD protocol is zero-knowledge, it is obvious that step 1 and 4 in $\S$ are indistinguishable from those in the real world of Construction~\ref{construction::zksumcheck}. It remains to show that the sumchecks in step 3 of both worlds are indistinguishable.
	
	To see that, recall that in round $i$ of the sumcheck protocol, $\V$ receives a univariate polynomial $h_i(x_i) = \sum\limits_{b_{i+1}, \ldots,b_\ell\in\binary}h(r_1, \ldots, r_{i-1},x_i, b_{i+1}, \ldots, b_\ell)$ where $h = f+\rho g$. (The view of $\V^*$ is defined in the same way with $h^*,f^*,g^*$ and we omit the repetition in the following.) As the variable degree of $f$ and $g$ is $d$, $\P$ sends $\V$ $h_i(0), h_i(1), \ldots, h_i(d)$ which uniquely defines $h_i(x_i)$. These evaluations reveal $d+1$ independent linear constraints on the coefficients of $h$. In addition, note that when these evaluations are computed honestly by $\P$, $h_i(0)+h_i(1) = h_{i-1}(r_{i-1})$, as required in the sumcheck protocol. Therefore, in all $\ell$ rounds of the sumcheck, $\V$ and $\V^*$ receives $\ell(d+1) - (\ell-1) = \ell d+1$ independent linear constraints on the coefficients of $h$ and $h^*$. 
	
	As $h$ and $h^*$ are masked by $g$ and $g^*$, each with exactly $\ell d+1$ coefficients selected randomly, the two linear systems are identically distributed. Therefore, step 3 of the ideal world is indistinguishable from that of the real world.
	
\end{proof}

\section{Proof of Theorem~\ref{thm:zkgkr}}\label{app:proofgkr}

\begin{proof} With oracle access to $\mathsf{out}$, and the simulator $\S_{sc}$ of the zero-knowledge sumcheck protocol in Section~\ref{subsec:zksumcheck} as a subroutine, we construct the simulator $\mathcal{S}$ as following:

\begin{enumerate}

\item $\S$ sends the $\mathsf{out}$ to $\V^*$.

\item $\S$ randomly selects polynomials $R^*_1(z_1, w), \ldots, R^*_d(z_1, w): \F^2\rightarrow \F$ with variable degree 2. $\S$ commits to these polynomials by sending $\comm_i\leftarrow\Commit(R^*_i)$ to $\V^*$ for $i\in[1,d]$.

\item $\S$ receives $g^{(0)}$ from $\V^*$.

\item $\S$ calls $\S_{sc}$ to simulate the partial view of the zero knowledge sumcheck protocol on 
{\footnotesize
\[
\dot{V}_{0}(g^{(0)})=\sum_{x, y\in \binary^{s_{1}}}\tilde{mult}_{1}(g^{(0)}, x, y)(\dot{V}_{1}(x)\dot{V}_{1}(y))+\tilde{add}_{1}(g^{(0)},x,y)(\dot{V}_{1}(x)+\dot{V}_{1}(y))
\]
}
If $u_1^{(1)} = v_1^{(1)}$, $\S$ aborts. At the end of the sumcheck, $\S$ samples $\dot{V}^*_1(u^{(1)})$ and $\dot{V}^*_1(v^{(1)})$ such that $\tmult_1(g^{(0)},u^{(1)},v^{(1)})\dot{V}^*_1(u^{(1)})\dot{V}^*_1(v^{(1)})+\tadd_1(g^{(0)},u^{(1)},v^{(1)})$ $(\dot{V}^*_1(u^{(1)})+\dot{V}^*_1(v^{(1)}))$ equals to the last message of the sumcheck.

\item For layer $i=1,\ldots,d-1$:
	\begin{enumerate}
	\item $\S$ receives $\alpha^{(i)}, \beta^{(i)}$ from $\V^*$.
	\item Let $Mult_{i + 1}(x, y) = \alpha^{(i)}\tilde{mult}_{i+1}(u^{(i)}, x, y)+\beta^{(i)}\tilde{mult}_{i+1}(v^{(i)}, x, y)$ and $Add_{i + 1}(x, y) = \alpha^{(i)}\tilde{add}_{i+1}(u^{(i)}, x, y)+\beta^{(i)}\tilde{add}_{i+1}(v^{(i)}, x, y)$. $\S$ calls $\S_{sc}$ to simulate the partial view of the zero knowledge sumcheck protocol on \\
	
	$\alpha^{(i)}\dot{V}_i(u^{(i)})+\beta^{(i)}\dot{V}_i(v^{(i)})=$
	\begin{align*}
	&\sum_{\substack{x, y\in \binary^{s_{i+1}}\\w \in \binary}}(I(\vec{0},w) \cdot Mult_{i+1}(x, y)(\dot{V}_{i+1}(x)\dot{V}_{i+1}(y))\\
	&+Add_{i+1}(x, y)(\dot{V}_{i+1}(x)+\dot{V}_{i+1}(y))\nonumber\\
	&+ I((x, y), \vec{0})(\alpha^{(i)}Z_i(u^{(i)})R_i(u_1^{(i)}, w)+\beta^{(i)}Z_i(v^{(i)})R_i(v_1^{(i)}, w)))
	\end{align*}
	If $u_1^{(i+1)} = v_1^{(i+1)}$, $\S$ aborts.
	
	\item At the end of the zero-knowledge sumcheck protocol, if $u_1^{(i+1)} = v_1^{(i+1)}$, $\S$ aborts. Otherwise, $\S$ samples $\dot{V}^*_{i+1}(u^{(i+1)})$ and $\dot{V}^*_{i+1}(v^{(i+1)})$ randomly such that the following equals to the last message of the sumcheck protocol.
	{\footnotesize
	\begin{align*}
	I(\vec{0},c^{(i)})(a_{i+1}(\dot{V}^*_{i+1}(u^{(i+1)})\dot{V}^*_{i+1}(v^{(i+1)}))+b_{i+1}(\dot{V}^*_{i+1}(u^{(i+1)})+\dot{V}^*_{i+1}(v^{(i+1)})))\\
	+I((u^{(i+1)},v^{(i+1)}),\vec{0})(\alpha^{(i)}Z_i(u^{(i)})R^*_i(u_1^{(i)}, c^{(i)})+\beta^{(i)}Z_i(v^{(i)})R^*_i(v_1^{(i)}, c^{(i)}))
	\end{align*}
	}
	$a_{i+1} = \alpha^{(i)}\tilde{mult}_{i+1}(u^{(i)}, u^{(i+1)}, v^{(i+1)})+\beta^{(i)}\tilde{mult}_{i+1}(v^{(i)}, u^{(i+1)}, v^{(i+1)})$ and $b_{i+1} = \alpha^{(i)}\tilde{add}_{i+1}(u^{(i)}, u^{(i+1)}, v^{(i+1)})+\beta^{(i)}\tilde{add}_{i+1}(v^{(i)}, u^{(i+1)}, v^{(i+1)})$. $\S$ sends $\dot{V}_{i+1}(u^{(i+1)})$ and $\dot{V}_{i+1}(v^{(i+1)})$ to $\V^*$.
	
	\item $\V^*$ computes the corresponding values locally as in step 5(d) of Construction~\ref{construction:zkgkr}.
	\item $\S$ opens $R^*_i$ at two points $R^*_i(u_1^{(i)},c^{(i)})$ and $R^*_i(v_1^{(i)},c^{(i)})$ using $\Open$.
	\item $\V^*$ performs the checks as in step 5(f) of Construction~\ref{construction:zkgkr}.
	\end{enumerate}
\end{enumerate} 

Note here that $\V^*$ can actually behave arbitrarily in step 5(d) and 5(f) above. We include these steps to be consistent with the real world in  Construction~\ref{construction:zkgkr} for the ease of interpretation.

To prove zero-knowledge, step 1,3, 5(a), 5(d) and 5(f) are obviously indistinguishable as $\S$ only receives messages from $\V^*$. Step 2 and 5(e) of both worlds are indistinguishable because of the zero knowledge property of the zkVPD, and the fact that $R^*$ and $R$ are sampled randomly in both worlds. Step 4 and 5(b) are indistinguishable as proven in Theorem~\ref{thm:zksc} for $\S_{sc}$.  


It remains to consider the messages received at the end of step 4 and in step 5(c), namely $\dot{V}_{i}(u^{(i)}), \dot{V}_{i}(v^{(i)})$ and $\dot{V}^*_{i}(u^{(i)}), \dot{V}^*_{i}(v^{(i)})$ for $i = 1,\ldots,d$. In the real world, $\dot{V}_{i}(z)$ is masked by $\sum\limits_{w \in\binary}R_i(z_1,w)$ ($Z(z)$ is publicly known), thus $\dot{V}_{i}(u^{(i)})$ and $\dot{V}_{i}(v^{(i)})$ are masked by $\sum\limits_{w \in\binary}R_i(u_1^{(i)},w)$ and $\sum\limits_{w \in\binary}R_i(v_1^{(i)},w)$ correspondingly. In addition, in step 5(e), $\V^*$ opens $R_i$ at $R_i(u_1^{(i)},c^{(i)})$ and $R_i(v_1^{(i)},c^{(i)})$. To simplify the notation here, we consider only a particular layer and omit the subscription and superscription of $i$. Let $R(z_1,w) = a_0+a_1z_1+a_2w+a_3z_1w+a_4z_1^2+a_5w^2+a_6z_1^2w^2$, where $a_0,\ldots,a_6$ are randomly chosen. We can write the four evaluations above as 
\[
\begin{bmatrix}
2 & 2u_1 & 1 & u_1 & 2u_1^2 & 1 & u_1^2\\
2 & 2v_1 & 1 & v_1& 2v_1^2 & 1 & v_1^2\\
1 & u_1 & c & cu_1 & u_1^2 & c^2 & c^2u_1^2\\
1 & v_1 & c & cv_1 &  v_1^2 & c^2 & c^2v_1^2\\
\end{bmatrix}
\times
\begin{bmatrix}
a_0 & a_1 &a_2 &a_3&a_4&a_5&a_6
\end{bmatrix}^T
\]
After row reduction, the left matrix is
\[
\begin{bmatrix}
2 & 2u_1 & 1 & u_1 & 2u_1^2 & 1 & u_1^2\\
0 & 2(v_1-u_1) & 0 & v_1-u_1 & 2(u_1^2-v_1^2) & 0 & u_1^2-v_1^2\\
0 & 0 & 2c-1 & (2c-1)u_1 & 0 & 2c^2-1 & (2c^2-1)u_1^2\\
0 & 0 & 0 & (2c-1)(v_1-u_1)&0 & 0 & (2c^2-1)(v_1^2-u_1^2)\\
\end{bmatrix}
\]
As $u_1\neq v_1$, the matrix has full rank if $2c^2 - 1\neq 0 \mod p$, where $p$ is the prime that defines $\F$. This holds if $2^{-1}$ is not in the quadratic residue of $p$, or equivalently $p \not\equiv 1, 7 \mod 8$.\footnote{From the reduced matrix, we can see that setting $a_2 = a_3 = a_4 = 0$ does not affect the rank of the matrix, which simplifies the masking polynomial $R$ in practice.} In case $p\equiv 1, 7 \mod 8$, we can add a check to both the protocol and the simulator to abort if $2c^2 -1 =0$. This does not affect the proof of zero knowledge, and only reduces the soundness error by a small amount. \footnote{If one is willing to perform a check like this, we can simplify the masking polynomial $R$ to be multilinear. The reduced matrix will be the first 4 columns of the matrix showed above, and it has full rank if $c\neq 2^{-1}$.}


Because of the full rank of the matrix, the four evaluations are linearly independent and uniformly distributed, as $a_0,\ldots a_6$ are chosen randomly. In the ideal world, $R^*(u_1,c)$ and $R^*(v_1,c)$ are independent and uniformly distributed, and $\dot{V}^*(u), \dot{V}^*(v)$ are randomly selected subject to a linear constraint (step 5(c)), which is the same as the real world. Therefore, they are indistinguishable in the two worlds, which completes the proof.   



\end{proof}


\section{zkVPD Protocol for the Input Layer}\label{app:zkvpdconstruction}

\begin{figure}[t!]
	\small{
		\centering{\centering
			\framebox{\parbox{.99\linewidth}{
					\begin{construction}
						\label{construction::zkVPD}
						Let $\mathbb{F}$ be a prime-order finite field. Let $\dot{V}(x): \F^\ell\rightarrow \F$ be an $\ell$-variate polynomial such that $\dot{V}(x) = \tV(x)+Z(x)R(x_1)$, where $\tV(x)$ is a multilinear polynomial, $Z(x) = \prod_{i=1}^\ell x_i(1-x_i)$ and $R(x_1) = a_0+a_1x_1$. 
						
						
						\begin{itemize}
							\item $(\pp, \vp) \leftarrow \KeyGen(1^\lambda, \ell)$: Select $\alpha, t_1, t_2, \cdots, t_l, t_{\ell+1} \in \F$ uniformaly at random, run $\mathsf{bp} \leftarrow \mathsf{BilGen}(1^{\lambda})$ and compute $\pp = (\mathsf{bp},g^\alpha, g^{t_{\ell+1}}, g^{\alpha t_{\ell+1}}, \{g^{\prod_{i\in W}t_i}, g^{\alpha\prod_{i\in W}t_i}\}_{W\in \mathcal{W}_\ell})$, where $\mathcal{W}_\ell$ is the set of all subsets of $\{1,\ldots, \ell\}$. Set $\vp = (\mathsf{bp},g^{t_1}, \ldots, g^{t_{\ell+1}}, g^\alpha)$.
							
							
							\item $\comm \leftarrow \Commit(\dot{V}, r_V, r_R, \pp)$: Compute $c_1 = g^{\tV(t_1, t_2, \cdots, t_\ell) + r_Vt_{\ell+1}}$, $c_2 = g^{\alpha(\tV(t_1, t_2, \cdots, t_\ell) + r_Vt_{\ell+1})}$, $c_3 = g^{R(t_1)+r_Rt_{\ell+1}}$ and $c_4 = g^{\alpha(R(t_1)+r_Rt_{\ell+1})}$  output the commitment $\comm = (c_1, c_2,c_3,c_4)$.
							
							\item $\{\accept,\reject\}\leftarrow\CheckComm(\comm, \vp)$: Output $\accept$ if $e(c_1, g^\alpha) = e(c_2,g)$ and $e(c_3, g^\alpha) = e(c_4,g)$. Otherwise, output $\reject$.
							
							\item $(y,\pi)\leftarrow\Open(\dot{V}, r_V, r_R, u,\pp)$: Choose $r_1,\ldots, r_\ell\in\F$ at random, and compute polynomials $q_i$ such that
							\[
							\tV(x)+r_Vx_{\ell+1}+Z(u)(R(x_1)+r_Rx_{\ell+1}) -(\tV(u)+Z(u)R(u_1)) =
							\]
							\[ \sum_{i=1}^\ell(x_i-u_i)(q_i(x_i,\ldots,x_\ell)+r_ix_{\ell+1})+x_{\ell+1}(r_V+r_RZ(u)-\sum_{i=1}^\ell r_i(x_i-u_i)).
							\]   
							Set $\pi = (\{g^{q_i(t_i\ldots, t_\ell)+r_it_{\ell+1}}, g^{\alpha(q_i(t_i\ldots, t_\ell)+r_it_{\ell+1})}\}_{i\in[1,\ell]},$ $ g^{r_V+r_RZ(u)-\sum_{i=1}^\ell r_i(t_i-u_i)}, g^{\alpha(r_V+r_RZ(u)-\sum_{i=1}^\ell r_i(t_i-u_i))})$ and $y = \tV(u)+Z(u)R(u_1)$.
							
							\item $\{\accept,\reject\}\leftarrow\Verify(\comm,u,y,\pi,\vp)$: Parse $\pi$ as $(\pi_i,\pi_{\alpha i})$ for $i\in[1,\ell+1]$. Check $e(\pi_i,g^\alpha) = e(\pi_{\alpha i},g)$ for $i\in[1,\ell+1]$. Check $e(c_1c_3^{Z(u)}/g^y, g) = \prod_{i=1}^\ell e(\pi_i, g^{t_i-u_i}) \cdot e(g^{\pi_{\ell+1}},g^{t_{\ell+1}})$. Output $\accept$ if all the checks pass, otherwise, output $\reject$.
							
							
						\end{itemize} 
						
	\end{construction}}}}}
\end{figure}

\section{Additional Optimizations for \name}\label{app:opt}

\paragraph{Key generation with look-up tables.} There is a setup phase in our zkVPD protocol, where the generator $g$ of the bilinear map base group is raised to $O(n)$ different powers. We developed an algorithm with look-up tables that improves this setup time by $\frac{\log n}{2}$. 

The bit-length of these powers is $\log |\F|$, as they are products of the secret keys selected randomly. We divide the $\log|\F|$ bits into $\frac{2\log|\F|}{\log n}$ blocks with $\frac{\log n}{2}$ bits each. For each block, we consider all $i\in\binary^{\log n/2}$ in the block and set the bits of other blocks as 0. We precompute the powers of $g$ to all possible values in each block as the look-up table. The space and time of this step is $O(\frac{2\log|\F|}{\log n}\cdot\sqrt{n})$. To compute a power $g^a$, we divide the bits of $a$ into such blocks. The contribution of each block can be computed in constant time by the look-up table, and we simply multiply them together to get $g^a$. The computation takes $O(\frac{2\log|\F|}{\log n})$ time, while without this optimization, each exponentiation takes $O(\log |\F|)$ time.

Concretely, the optimization improves the setup time by around $10\times$ in practice, and can also be applied to the setup in SNARKs.

\paragraph{More gate types with no overhead.} In our protocol, we only consider addition and multiplication gates, as they are enough to represent all arithmetic circuits. However, in practice, the size of the circuit can be reduced significantly if we introduce other types of gate. The GKR protocol still works with these new gates, but they incur an overhead on the prover time for a circuit of the same size. Therefore, in prior work such as~\cite{wahby2016verifiable,vram}, this is considered as a trade-off.

Our protocol supports any gate with fan-in $\le 2$ and degree $\le 2$ with no overhead on the prover. Recall that in the GKR protocol, the values in layer $i$ is represented as a sumcheck of values in layer $i+1$ and the wiring predicates, as shown in Equation~\ref{eq:GKR}. With a set of gate types $\mathcal{T}$, we can write the polynomial in the sum as $$\sum_{j\in\mathcal{T}}\tilde{gate}^{(j)}_i(g,x,y) G^{(j)}_i(\tV_{i+1}(x),\tV_{i+1}(x)),$$ where $G^{(j)}_i()$ is the computation of gate type $j$ (e.g., for addition gates, \\$G^{(j)}_i(\tV_{i+1}(x),\tV_{i+1}(x)) = \tV_{i+1}(x)+\tV_{i+1}(x)$). As the gates have fan-in $\le 2$ and degree $\le 2$, $G^{(j)}_i$ has up to 2 variables and total degree at most 2 for all $j$. Therefore, each $G^{(j)}_i$ can be expressed explicitly as $a_0+a_1\tV_{i+1}(x)+a_2\tV_{i+1}(y)+a_3\tV_{i+1}(x)\tV_{i+1}(y)+a_4\tV_{i+1}(x)^2+a_5\tV_{i+1}(y)^2$, at most 6 nonzero monomials. The prover can then combine all the wiring predicates $\tilde{gate}^{(j)}_i(g,x,y)$ for the same monomial through a summation. With this approach, when generating the proof in Algorithm~\ref{alg::phase1} and~\ref{alg::phase2}, the prover only allocates one array for each monomial, and initializes all 6 arrays with one scan through all the gates in $\mathsf{Init\_PhaseOne}$ and $\mathsf{Init\_PhaseTwo}$. In this way, the prover time remains the same regardless of the number of gate types. 

In our experiments, useful types of gates include subtraction, relay, multiply by constant, $x(1-x)$ for binary check, \texttt{NOT,AND,OR,XOR}, etc. 